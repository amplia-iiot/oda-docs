[
  {
    "content": "Connectors The connectors layer handle data at low level to send it and receive it to/from the Internet.\nThe action of sending data to the Internet is called uplink and all connectors must be able to implement it.\nSome connectors are able to receive operations from third systems (usually OpenGate) and answer with the operation response. This feature is implemented in a message received callback. Available operations are defined in operations section\nOpenGate Connectors The OpenGate connectors modules are responsible for sending the byte stream to Internet through the implemented protocol.\nThe following protocols are implemented in ODA:\nCoAP: Allow to send IoT data and receive operations HTTP: Allow to send IoT data. WebSocket: Allow to send IoT data and receive operations. MQTT: Allow to send IoT data and receive operations. To add new protocols you have to implement the OpenGateConnector interface:\npublic interface OpenGateConnector { void uplink(byte[] payload, ContentType contentType); boolean isConnected(); } The uplink method should send the byte array following the implemented protocol and add the content type if the protocol allows it.\nThe isConnected method is used to check if the connector is connected.\nSCADA connectors The SCADA connectors are specific connector for SCADA protocols that works at a higher level than byte array.\nThere are two available protocols:\nIEC 104 DNP3 To implement a new protocol the ScadaConnector should be implemented:\npublic interface ScadaConnector { void uplink(int index, T value, S type, long timestamp); boolean isConnected(); } The uplink method implement an uplink of the given type and value to the specified index and with the given timestamp.\nThe isConnected method is used to check if the connector is connected.\n",
    "description": "",
    "tags": null,
    "title": "Connectors",
    "uri": "/layers/connectors/index.html"
  },
  {
    "content": "Introduction This section will include schemas to explain the stages an event goes through from being read from a device to being published.\nPoller reads data from devices using the corresponding connector and passes it to the StateManager to be processed.\nDepending on the configuration, the behavior of the StateManager differs.\nIf we are using StateManager-RealTime, data will be sent to the dispatcher to be published.\nIf we are using StateManager-InMemory, data will be processed (using rule engine) and stored. We can also send the processed data directly to the dispatcher marking the data to be sent immediately. It is explained in more detail in events processing.\nThe collector, retrieves data stored in the StateManager-InMemory and sends it to the dispatcher. It is explained in more detail in events collection.\nDispatcher sends data (trough the necessary connector) to an external system.\n",
    "description": "",
    "tags": null,
    "title": "Events flow",
    "uri": "/guides/eventsflow/index.html"
  },
  {
    "content": "In StateManager- InMemory bundle, when a new event from a device arrives, it is processed executing a number of steps:\nRules associated to the datastreamId of the event are applied to the event. There can be N rules to be applied.\nOnce all rules have been applied, we retrieve from StateManager memory all the datastreamIds which have been marked as ‘refreshed’ (there is a new value for that datastreamId) or as ‘sendImmediately’.\nIf the datastreamId has been marked as ‘sendImmediately’, the event is parsed and saved in a list to be sent at the end of the process. The value in memory is marked as ‘sent’.\nIf the datastreamId has been marked as refreshed, the new values are saved in database (if the datastreamId was marked as ‘sendImmediately’ it will be saved in database with ‘sent’ = true, otherwise ‘sent’ = false). After saving the new values, it will be checked if it is needed to erase old data from database.\nOnce all events have been processed, those marked to send immediately will be passed along to the dispatcher to be published.\nThere are some things to consider:\nRefreshed and sendImmediately marks are applied to all the values of the datastreamId marked. This means that if inside the rules, we generate N new values, all of them will be marked.\nInside rules que can generate N new values for any datastreamId, not only the one from the event that triggers the process. Because of this, after applying the rules we must check all the datastreamIds that have been marked.\n",
    "description": "",
    "tags": null,
    "title": "Events processing",
    "uri": "/guides/eventsflow/eventsprocessing/index.html"
  },
  {
    "content": "Scada Tables This bundle is used by the IEC104 datastreams bundle. It defines the variables we want to retrieve from IEC104 devices and its corresponding ASDU.\nIts configuration file (es.amplia.oda.service.scadatables.cfg) has this format:\nASDU1, address1 = datastream: datastreamId1 ASDU2, address2 = datastream: datastreamId2 ... Every line represents an element read from the IEC104 device.\nThe ASDU indicates the type of the value read.\nThe address indicates the address where the value is stored in the IEC104 device.\nThe datastreamId indicates the Id of the datastream assigned to the value read.\nODA supports the next ASDUs:\nM_SP_NA_1 = Single Point M_DP_NA_1 = Double Point M_ME_NC_1 = Measured Float M_ST_NA_1 = Step Position M_BO_NA_1 = Bitstring M_ME_NA_1 = Measured Normalized M_ME_ND_1 = Measured Normalized (no quality information) M_ME_NB_1 = Measured Scaled ",
    "description": "",
    "tags": null,
    "title": "Scada Tables",
    "uri": "/layers/other/scadatables/index.html"
  },
  {
    "content": "The Core multi-module contains general interfaces, services and utils that may be used by the rest of the ODA modules.\nCommons The Commons module contains the APIs of global services and entities used by the whole system. It also contains utils to ease the development of new features in ODA.\nGlobal APIs The commons module contains the APIs for:\nConnectors Dispatchers Data streams SCADA services Serializers ADC GPIO I2C Modbus Proxies A set of proxies is provided to facilitate the ODA services consumption.\nCreate a service proxy every time you define a new service in ODA using the OsgiServiceProxy, easing the use of the service without worrying about OSGi ServiceTracker details.\nUtils Common utils to ease development of common tasks. Some of them are:\nScheduling tasks Locating a service Registering a service in the OSGi Registry … ",
    "description": "",
    "tags": null,
    "title": "Core",
    "uri": "/infrastructure/core/index.html"
  },
  {
    "content": "Datastreams Getters, Setters and Events The datastreams are the basic entity to model data inside a device. Datastreams are divided in:\nDatastreams Getters: Datastreams modelling data with read access. public interface DatastreamsGetter { String getDatastreamIdSatisfied(); List\u003cString\u003e getDevicesIdManaged(); CompletableFuture\u003cCollectedValue\u003e get(String device); } Datastreams Setters: Datastreams modelling data with write access. public interface DatastreamsSetter { String getDatastreamIdSatisfied(); Type getDatastreamType(); List\u003cString\u003e getDevicesIdManaged(); CompletableFuture\u003cVoid\u003e set(String device, Object value); } Datastreams Events: Datastreams modelling data that trigger data events. public interface DatastreamsEvent { void registerToEventSource(); void unregisterFromEventSource(); void publish(String deviceId, String datastreamId, List\u003cString\u003e path, Long at, Object value); } This layer abstract different data sources modelling them as datastreams, easing the access to read, write and send events.\n::: tip When a new data source is identified try to abstract the hardware access in a new API in the hardware layer and create a new datastreams abstraction using the defined hardware API :::\nImplemented datastreams data sources The following data sources are implemented and abstracted as datamodels:\nADC: Device ADC pins. Device Info: Information about the device as CPU, Memory, Clock, Software… GPIO: Device GPIO pins. I2C: Data inside I2C devices (sensors and microcontrollers). Modbus: Data measured by connected devices through Modbus protocol. MQTT: Data measured by connected devices through MQTT protocol. IEC104: Data measured by connected devices through Iec104 protocol. Simulator A simulator datastreams implementation is provided to simulate data with debugging and demonstration purposes.\n",
    "description": "",
    "tags": null,
    "title": "Datastreams",
    "uri": "/layers/datastreams/index.html"
  },
  {
    "content": "In Collector bundle, when we have to collect events stored in StateManager memory a number of steps is executed:\nGet from memory all events whose datastreamId and deviceId are equals to the ones that triggered the process (all those configured in the collector config file for this moment).\nGet from database all existing values for the datastreamId and deviceId indicated.\nUsing the values obtained from the database, all values stored in memory are updated. The update only affects the ‘sent’ indication. If in the values in database it is indicated that the value has already been sent, we update the value in memory to indicate the same. If it indicates that it has’nt been sent, we do the same.\nOnce all values in memory have been updated, we get all values that haven’t been sent.\nWe update the ‘sent’ indication for these values in database.\nOf all the values collected, filter out those whose status is not okay.\nThe values that are OK, are sent to the dispatcher to be published.\nIn OpenGate Dispatcher, for every event it is checked if the datastreamId of the event is defined in the dispatcher configuration. If it is, the event is saved in a list to be published when the dispatcher indicates. If it is not defined in the dispatcher, it will be send immediately.\nWe can see the relation between the collector and dispatcher in the next schema:\n",
    "description": "",
    "tags": null,
    "title": "Events collection",
    "uri": "/guides/eventsflow/eventscollection/index.html"
  },
  {
    "content": "ODA provides a common infrastructure to be used from any module:\nCore: Core modules with common features. Comms: Communication modules used by different modules of the system. Services: Services to be used by any module (e.g. serialization services). Subsystems: General subsystems. ",
    "description": "",
    "tags": null,
    "title": "Infrastructure",
    "uri": "/infrastructure/index.html"
  },
  {
    "content": "Load bundle in OpenGate To be able to install a bundle in ODA, first we must load the bundle in OpenGate.\nWe go to the option Create new bundle and follow the wizard instructions. There are some considerations when filling the wizard fields:\nThe name of the bundle must be equal to the symbolic name of the bundle defined in pom file.\nThe hardware and workgroup assigned to the bundle must be the same as the fields Model and Organization of the entity in which we want to install the bundle.\nChoose operation INSTALL, type SOFTWARE and the file corresponding to the bundle we want to deploy.\nThe route parameter must be the same value as deployPath in configuration file.\nWhen the wizard is finished, the bundle has been uploaded to OpenGate. We must check that the bundle is activated before we can launch the UPDATE operation against ODA. If it is not activated (there is an option to activate the bundle when we upload it to OpenGate), we can activate from the bundle list widget, clicking in the three dots at the side of the bundle.\nOnce this is done, we launch the execute operation wizard, select the Device Update operation and fill the name of the bundle we want to install and its version.\nBundle installation in ODA When ODA receives the UPDATE operation, it will download the bundle into the folder specified in downloadsPath parameter in configuration file (this parameter must end with ‘/’).\nOnce the bundle is downloaded it will try to install it. If everything was right, we will see these messages in log file:\nBundleEvent INSTALLED - the bundle has been installed\nBundleEvent RESOLVED - the bundle dependencies have been resolved\nBundleEvent STARTED - the bundle has been started\nIf there is an error while installing the bundle, ODA will try to do a rollback to return to previous state.\n",
    "description": "",
    "tags": null,
    "title": "Install bundles",
    "uri": "/scenarios/updatesoftware/bundles/index.html"
  },
  {
    "content": "Request data periodically from devices Using ODA capabilities we can request data periodically from a device using one of the interfaces defined in ODA.\nConfigure the hardware connection to the device. This is done in the corresponding configuration file of that hardware interface es.amplia.oda.hardware.*.cfg. To know the parameters needed to configure the hardware interface we want to use, check the Layers/Hardware section in this guide.\nConfigure the datastream that will contain the data retrieved by the hardware layer. This is done in the corresponding datastream configuration file es.amplia.oda.datastreams.*.cfg. The parameters needed to configure the datastreams are in the Layers/Datastream section in this guide.\nThe last step is to configure the poller to ask for data for the datastream we have configured. This is done by adding a new line in the configuration file es.amplia.oda.subsystem.poller.cfg with the format:\ndatastreamId;deviceId=firstPollingInSeconds;nextPollingInSeconds;\nLastly, if we want to retrieve data from an interface ODA does not support, we can develop our own solution using ODA capabilities as we see in Development section in this guide.\n",
    "description": "",
    "tags": null,
    "title": "Recollect Data",
    "uri": "/scenarios/recollectdata/index.html"
  },
  {
    "content": "The communications multi-module contains communication protocols that are used as LAN and WAN.\nWhen the same protocol is used to connect with the Internet, with OpenGate or other third services, and to connect with local devices, is better to create and abstraction of the protocol to reuse code in both sides. Usually this abstraction is a service providing a factory to create clients and servers of the protocol.\nProtocols MQTT The MQTT protocol is used to connect to OpenGate and also to connect with a MQTT broker in the local network to integrate devices in the local area.\nAn API is defined to create MQTT clients and to use them, decoupling from the chosen MQTT library implementation.\npublic interface MqttClientFactory { MqttClient createMqttClient(String serverUri, String clientId) throws MqttException; } The MQTT Client API is\npublic interface MqttClient { void connect(); void connect(MqttConnectOptions options); void subscribe(String topic, MqttMessageListener listener); void unsubscribe(String topic); void publish(String topic, MqttMessage message, ContentType contentType); boolean isConnected(); void disconnect(); } IEC104 The IEC104 protocol is used to connect to a SCADA third-system that implements an IEC 104 master (client).\nIt can be used to recollect data from a device and also to send data to an external SCADA system.\n",
    "description": "",
    "tags": null,
    "title": "Communications",
    "uri": "/infrastructure/comms/index.html"
  },
  {
    "content": "ODA uses configuration files to configure its bundles.\nThe name of the configuration file is the name of the java package where the code implementation that uses the properties is located.\nODA has these default configuration files:\nes.amplia.oda.harware.* - define properties of connectors used by ODA to connect with devices (south interface)\nes.amplia.oda.datastreams.* - define the characteristics of the datastreams that ODA creates when connecting with devices (south interface)\nes.amplia.oda.connector.* - define properties of connectors used by ODA to connect with internet (north interface)\nes.amplia.oda.dispatcher.opengate - defines datastreams for dispatcher to manage before sending to opengate. The dispatcher joins several datastreams with the same id into a one datastream with several datapoints.\nFormat: datastreamId;deviceId=firstPublishingInSeconds;nextPublishingsInSeconds\nes.amplia.oda.statemanager.inmemory - defines parameters for state manager in memory mode (path where database is located and time data is saved before being erased)\nes.amplia.oda.subsystem.collector - defines datastreams to collect from state manager and pass to dispatcher or send to internet if no dispatcher is defined\nFormat: datastreamId;deviceID=initialDelay;collectionPeriod\nes.amplia.oda.subsystem.poller - defines the datastreams to periodically poll data from device. Every x seconds the poller will execute the get method defined in a DatastreamGetter class with the same datastream and device ids.\nFormat: datastreamId;deviceId=firstPollingInSeconds;nextPollingInSeconds\nes.amplia.oda.datastreams.deviceinfo - define the properties of the device where ODA is installed (ID, api-key to connect to opengate,etc)\nes.amplia.oda.ruleengine.nashorn - defines the properties for nashron engine used to define rules\nes.amplia.oda.subsystem.sshserver - defines the properties of ssh server used to connect to framework\n",
    "description": "",
    "tags": null,
    "title": "Configuration files",
    "uri": "/guides/configfiles/index.html"
  },
  {
    "content": "In StateManager-InMemory bundle, events are stored in memory and in the database. We need a process that erases old events that are no longer needed to avoid using too much disk and memory. This process is done in different places and bundles.\nThere are three parameters in StateManager configuration file that are used in these process:\nmaxData - indicates how many values can be stored for any datastreamId, deviceId combination.\nExample: we have values for “datastreamId1:device1” and for “datastreamId2:device1” and the maxData parameter is set to 30. These means that we can have 30 values stores for “datastreamId1:device1” and another 30 values for “datastreamId2:device1”.\nforgetTime - indicates the maximum time difference can be between the stored events and the current moment. It is indicated in seconds.\nExample : we have forgetTime parameter set to 60 seconds. This means that only events from the last minute will remain stored.\nforgetPeriod - indicates how often we want to check if there is old data in database. It is indicated in seconds.\nErasure of older events in memory This is done in StateManager bundle. Its one of the steps done when processing new events generated from devices. When there is a new event for a combination of datastreamId and deviceId, we check if there are old events in memory for that combination to remove:\nIf there are more events than indicated by maxData parameter, older values will be deleted until there are left only maxData events. If after removing events by maxData parameter, we check if there are events older than forgetTime parameter. Erasure of older events in database This is done in two different places:\nIn StateManager bundle, when we are inserting a new event in the database, we check if it is time to erase old events in database by maxData parameter. This is done when forgetPeriod seconds have passed since the last check. Example : if forgetPeriod parameter is 60 seconds, this means that we only check if there are more events than indicated by maxData parameter if have passed at least 60 seconds since the last check. This can be more than 60 seconds because this check is only done when a new event is registered in the database.\nIn Collector bundle, there is a dedicated thread that erases every forgetPeriod seconds old events indicated by forgetTime parameter. ",
    "description": "",
    "tags": null,
    "title": "Events erasure",
    "uri": "/guides/eventsflow/eventserasure/index.html"
  },
  {
    "content": "Hardware The Hardware layer abstract hardware and LAN protocols details decoupling the hardware access and use from the device details.\nAnytime you need to access a specific hardware, abstract the access and actions in a new API and implement the concrete behavior in a new implementation module registered in OSGi.\nAvailable abstractions Below are the hardware abstractions currently implemented\nAT Server Server capable of sending and receiving AT Commands.\nImplement the following interface:\npublic interface ATManager { void registerEvent(String atEvent, Consumer\u003cATEvent\u003e function) throws AlreadyRegisteredException; void unregisterEvent(String atEvent); void registerCommand(String atCmd, Function\u003cATCommand, ATResponse\u003e commandHandler) throws AlreadyRegisteredException; void unregisterCommand(String atCmd); void process(String line); CompletableFuture\u003cATResponse\u003e send(ATCommand cmd, long timeout, TimeUnit unit); void send(ATEvent evt); } Comms module Module capable of registering to Internet using a PIN, APN, username and password.\npublic interface CommsManager { void connect(String pin, String apn, String username, String password, int connectionTimeout, long retryConnectionTimer); } ADC Service Abstraction of the Analog Digital Converter pins of the device.\npublic interface AdcService { AdcChannel getChannelByName(String channelName); AdcChannel getChannelByIndex(int index); Map\u003cInteger, AdcChannel\u003e getAvailableChannels(); } The AdcChannel definition is:\npublic interface AdcChannel { int getIndex(); int getPin(); String getName(); float getRange(); float getScaledValue(); float getUnscaledValue(); void addAdcPinListener(AdcChannelListener listener); void removeAllAdcPinListener(); void close(); } I2C I2C protocol abstraction to access I2C devices (sensors, microcontrollers, …).\npublic interface I2CService { I2CDevice getI2CFromAddress(int controller, int address); I2CDevice getI2CFromName(String name); List\u003cI2CDevice\u003e getAllI2CFromController(int controller); List\u003cI2CDevice\u003e getAllI2C(); } The I2C device is defined as follows:\npublic interface I2CDevice { int getAddress(); int getController(); String getName(); double readRawData() throws InterruptedException; double readScaledData() throws InterruptedException; ByteBuffer read(int count); byte readByte(); void write(float data); void writeByte(byte b); boolean isOpen(); void close(); } GPIO Access to device input/output digital pins\npublic interface GpioService { GpioPin getPinByName(String pinName); GpioPin getPinByName(String pinName, GpioDirection direction, GpioMode mode, GpioTrigger trigger, boolean activeLow, boolean initialValue); GpioPin getPinByIndex(int index); GpioPin getPinByIndex(int index, GpioDirection direction, GpioMode mode, GpioTrigger trigger, boolean activeLow, boolean initialValue); Map\u003cInteger, GpioPin\u003e getAvailablePins(); } The GPIO pin interface is:\npublic interface GpioPin { int getIndex(); String getName(); GpioDirection getDirection(); GpioMode getMode(); GpioTrigger getTrigger(); boolean isActiveLow(); boolean getInitialValue(); boolean isOpen(); void open(); void close(); boolean getValue(); void setValue(boolean value); void addGpioPinListener(GpioPinListener listener); void removeGpioPinListener(); } Modbus The Modbus module abstracts the communication with Modbus devices through a Modbus Master.\npublic interface ModbusMaster { void connect(); boolean readInputDiscrete(int unitId, int ref); Boolean[] readInputDiscretes(int unitId, int ref, int count); boolean readCoil(int unitId, int ref); Boolean[] readCoils(int unitId, int ref, int count); void writeCoil(int unitId, int ref, boolean value); void writeCoils(int unitId, int ref, Boolean[] values); Register readInputRegister(int unitId, int ref); Register[] readInputRegisters(int unitId, int ref, int count); Register readHoldingRegister(int unitId, int ref); Register[] readHoldingRegisters(int unitId, int ref, int count); void writeHoldingRegister(int unitId, int ref, Register register); void writeHoldingRegisters(int unitId, int ref, Register[] registers); void disconnect(); } ",
    "description": "",
    "tags": null,
    "title": "Hardware",
    "uri": "/layers/hardware/index.html"
  },
  {
    "content": "Load rule in OpenGate To be able to install a new rule in ODA, first we must load the rule in OpenGate.\nWe go to the option Create new bundle and follow the wizard instructions. There are some considerations when filling the wizard fields:\nThe name and version fields in bundle configuration tab are not important since rules doesn’t have versions and the name will be the one indicated when uploading file in deploy elements tab.\nThe hardware and workgroup assigned to the rule must be the same as the fields Model and Organization of the entity in which we want to install the rule.\nChoose operation INSTALL, type SOFTWARE and the file corresponding to the rule we want to deploy. The name defined in this tab will be the name of the javascript file containing the rule code created.\nThe route parameter must be the same value as the folder in which the rule must be installed (rulesPath/datastreamIds). Rules path is the one defined in configuration file es.amplia.oda.ruleengine.nashorn.cfg. The folder name must be composed of the datastreamIds we want the rule to apply, separated by the character ‘:’. If this folder doesn’t exist in ODA, it will be created.\nWhen the wizard is finished, the rule has been uploaded to OpenGate. We must check that the rule is activated before we can launch the UPDATE operation against ODA. If it is not activated (there is an option to activate the rule when we upload it to OpenGate), we can activate from the bundle list widget, clicking in the three dots at the side of the rule.\nOnce this is done, we launch the execute operation wizard, select the Device Update operation and fill the name of the rule we want to install and its version (must be the same values we registered the rule with).\nRule installation in ODA When ODA receives the UPDATE operation, it will download the rule into the folder specified in downloadsPath parameter in configuration file (this parameter must end with ‘/’).\nFor ODA to be able to load the rule, the file utils.js (located in oda-ruleengine/api/src/main/resources/utils.js) must be copied in rulesUtilsPath folder as the rule downloaded will load it. Other javascript files the rule must load to be executed must be in these folder too.\nOnce the rule is downloaded it will try to install it. If everything was right, we will see the message Created rule rulesPath/datastreamIDs/ruleName.js in the log file.\nIf there is an error while installing the bundle, ODA will try to do a rollback to return to previous state.\nUpdate existing rule If we want to load a new version of a rule already installed in ODA, the process is the same, we upload the new rule to OpenGate but in the deploy elements tab, we choose UPGRADE as operation, we fill parameters as old name (must be the same as new name), old version (doesn’t matter in this case) and old route (must be the same as new route). We fill the rest of the parameters as if it is a new rule and launch the Device Update operation.\nWhen the operation reaches ODA the process is the same as installing a new rule. If everything was right, we will see the message Created rule rulesPath/datastreamIDs/ruleName.js in the log file.\nUpdate rules utils files Rules utils files are javascript files whose methods are invoked by rules. ODA has a main utils file called utils.js but we can create our own utils file apart from this one and save there methods used by rules to avoid writing the same method in every rule.\nThese files can also be updated through OpenGate. The method to install and update these files is the same as any rule. We deploy these elements in OpenGate as if it is a rule.\nWhen ODA installs or update any of these files, all existing rules in ODA will be reloaded to apply these new methods.\n",
    "description": "",
    "tags": null,
    "title": "Install rules",
    "uri": "/scenarios/updatesoftware/rules/index.html"
  },
  {
    "content": "ODA is composed of the following layers:\nConnectors: Send and received data to/from the Internet at a low level of abstraction (byte array). Operation Dispatcher: Converts from low level data into high level representation to process operations and send the responses. Event Dispatcher: Converts data events into a low level data representation to send it through the connectors. Operations: Implements a specific operation inside the device. State Manager: Stores the device data state in the current moment. Rule Engine: Triggers custom business logic rules over the device data. Datastreams: Abstracts the data sources to ease the access to read and write data from the upper layers. Hardware: Abstracts the hardware specifics. ",
    "description": "",
    "tags": null,
    "title": "Layers",
    "uri": "/layers/index.html"
  },
  {
    "content": "Publish data recollected from devices Once we have recollected data from the device, we must publish that data to OpenGate or another external system. There are two modes in which ODA can work to publish data:\nReal time - datastreams are published as soon as they are recollected from the poller\nIn memory - datastreams are stored in a database awaiting to be published\nIn real time mode, there is no configuration to be done. Once the poller gets the data from the device, it will be published.\nIn memory mode, the data recollected by the poller will be stored in the state manager, waiting for it to be published.\nIn memory mode To publish data wen using in memory mode of the state manager, we can use the collector capabilities from ODA.\nTo configure the collector we must add a line in the configuration file es.amplia.oda.subsystem.collector.cfg with the format indicated:\ndatastreamId;deviceId=firstCollectingInSeconds;nextCollectingInSeconds\nIndicating the id of the datastream and devices we want to collect, every x seconds ODA will collect from the state manager the datastreams that matches the ids indicated.\nIf no dispatcher is configured, the datastreams retrieved by the collector will be sent inmediately to the external system.\nIf a dispatcher is configured in the file es.amplia.oda.dispatcher.opengate.cfg, it will collect all datastreams with the datastreamId indicated, and will merge all in a single datastream with multiple datapoints. The format is the same as in the collector:\ndatastreamId;deviceId=firstPublishingInSeconds;nextPublishingsInSeconds\nThe whole recollection process can be seen in the next picture\nConnectors To publish data to an external system, ODA needs to know the protocol that it must use to publish that data to the internet (mqtt, http, etc). This is done trought the connectors layer.\nConnectors are defined in configuration files with names like this es.amplia.oda.connector.*.cfg , where * is the name of the connector (mqtt, http, etc).\nWe can have multiple connectors configured, ODA will publish the data trought all of them.\n",
    "description": "",
    "tags": null,
    "title": "Publish Data",
    "uri": "/scenarios/publishdata/index.html"
  },
  {
    "content": "Apply rules to the collected data ODA allows to configure custom rules to be applied after the data is collected from the device. Rules are only applied if we are using in memory state manager.\nRules are javascript files composed of two methods:\nwhen - this method defines the conditions that must be met for the rule to apply. Returns boolean indicating if the result is true or false. then - this method defines the changes we want to apply to the datastream. It is only executed if the when method returns true. Returns a new state. This methods have the same two inputs:\nState - defines the state of the state manager. DatastreamValue - defines a datastream with a value We can use the methods defined in file utils.js to make changes to the datastream that activates the rule. We can also implement our own methods inside the javascript file.\nUsing the nashorn engine we can use java objects and its methods in javascript.\nThe methods defined in utils.js are located in the classes State and DatastreamValue in the package es.amplia.oda.core.commons.utils\nWe can use single line comments inside the rule, they will be ignored when loading the rule inside the rule engine.\nWe can also use functions to log messages from inside the rule to ODA log file using the functions logInfo, logDebug, logError, logWarn, logTrace from State class as in this example:\nState.logInfo(\"Year = {}, Month = {}, Day = {}\", var1, var2, var3); Rules configuration To be able to apply rules we must first configure ODA to tell it the directory where the rules to apply will be stored.\nTo do this, we create a configuration file with the name es.amplia.oda.ruleengine.nashorn.cfg. In this file there are two parameters:\npath: Path from the main directory of the ODA to the directory where the rules are stored. utilsPath: Path from the main directory of the ODA to the directory where javascript files with utils methods used by rules are stored. Rules application Rules are applied to specific datastreams. This is determined by the folder name where rules are stored. This folder must be named like the datastreams we want those rules to apply to, separated by the character ‘:’.\nTo create a new rule we must create a folder with the ids of the datastreams (separated by the character’:’) we want to affect as folder name, inside the folder defined in the configuration file (path parameter in configuration file). Inside the folder of the datastreams, we will have to create the javascript files with the rules we want to apply. We can have many rules, all will be applied to the datastreams indicated in the folder name. The javascript files containing the rule code, can have any name we want.\nExample:\nWe have two datastreams: ‘value1’ and ‘value2’. The folder where rules are stored is called ‘rules’. If we want to create rules that affect both datastreams we must create a folder named ‘value1:value2’ inside the folder ‘rules’. Inside this folder we can have as many rules (javascript files) as we want, all of them will be applied to both datastreams. If we want rules that only affect datastream value1, we create a folder named value1 inside the folder ‘rules’.\nRules utils Rules utils files are javascript files whose methods can be invoked by rules. ODA has a main utils file called utils.js but we can create our own utils file apart from this one and write there methods used by rules to avoid writing the same method in every rule.\nTo use methods from another javascript file inside a rule, we must load that javascript file in the rule. This is done with the load method indicating the name of the javascript file to load.\nExample : load(“example.js”).\nThis javascript files must be placed in the folder defined by parameter utilsPath.\nThe methods in file utils.js are loaded by ODA for every rule, there is no need to explicitly load utils.js in every rule.\n",
    "description": "",
    "tags": null,
    "title": "Apply Rules",
    "uri": "/scenarios/applyrules/index.html"
  },
  {
    "content": "We explain here the different folders that compose ODA:\nConfiguration\nStores all configuration files used by ODA bundles. If ODA is running, changes made in these configuration files are loaded instantly.\nDeploy\nStores all ODA bundles that are installed in the framework.\nIf we add a new bundle in this folder, the framework will install and start it.\nIf we remove a bundle from this bundle, the framework will stop and uninstall it.\nLog\nStores the log files generated by ODA.\nThe file ODA.log contains the log of the current day.\nThe logs of previous days are saved in archived folder.\nBundle\nStores all bundles that are not part of ODA (Apache Felix framework bundles, log, etc).\n",
    "description": "",
    "tags": null,
    "title": "Folders",
    "uri": "/guides/folders/index.html"
  },
  {
    "content": "Here we are going to see some examples of things we can do with ODA as it is.\nRecollect data from devices\nPublish data recollected from devices\nApply rules to data recollected\nInstall bundle from OpenGate\nRead data from IEC104 devices\n",
    "description": "",
    "tags": null,
    "title": "Scenarios",
    "uri": "/scenarios/index.html"
  },
  {
    "content": "This multi-module contains services used by other bundles in ODA.\nImplemented services Serialization Serialization is a common feature to communicate to other local or global systems where different serialization formats may be required.\nA common serialization API has been created to call these services, independently of the required format:\npublic interface Serializer { byte[] serialize(Object value) throws IOException; \u003cT\u003e T deserialize(byte[] value, Class\u003cT\u003e type) throws IOException; } Currently, two serialization implementations are provided:\nJSON CBOR To add a new serialization format, just implement the Serializer interface contained in core module and register the service in the OSGi registry\nScada Tables This bundle is used by the IEC104 datastreams bundle. It defines the information needed to translate variables retrieved from a SCADA system to ODA events.\n",
    "description": "",
    "tags": null,
    "title": "Services",
    "uri": "/infrastructure/services/index.html"
  },
  {
    "content": "State Manager The State Manager stores the device data state in the current moment to ease the data access from operations and increase the system performance (at a expense of possible outdated data).\nStoring the state of all data in the device allow us to calculate inferred data (e.g. datastream statistical information) and execute smart actions depending on data that enables Edge Computing features.\nThere are different State Managers implementations depending on project needs. New State Managers may be added implementing the StateManager interface:\npublic interface StateManager { CompletableFuture\u003cDatastreamValue\u003e getDatastreamInformation(String deviceId, String datastreamId); CompletableFuture\u003cSet\u003cDatastreamValue\u003e\u003e getDatastreamsInformation(String deviceId, Set\u003cString\u003e datastreamIds); CompletableFuture\u003cSet\u003cDatastreamValue\u003e\u003e getDatastreamsInformation(DevicePattern devicePattern, String datastreamId); CompletableFuture\u003cSet\u003cDatastreamValue\u003e\u003e getDatastreamsInformation(DevicePattern devicePattern, Set\u003cString\u003e datastreamId); CompletableFuture\u003cSet\u003cDatastreamValue\u003e\u003e getDeviceInformation(String deviceId); CompletableFuture\u003cDatastreamValue\u003e setDatastreamValue(String deviceId, String datastreamId, Object value); CompletableFuture\u003cSet\u003cDatastreamValue\u003e\u003e setDatastreamValues(String deviceId, Map\u003cString, Object\u003e datastreamValues); void onReceivedEvents(List\u003cEvent\u003e events); void publishValues(List\u003cEvent\u003e event); void close(); } State Manager implementations The currently implemented state managers are:\nReal-time State Manager: The real time state manager is a proxy that works without storing any state and always getting and setting the data from/to the data source. It is the choice for projects with real-time concerns and without edge computing needs. In-Memory State Manager: The in-memory state manager store the state of all the data in the device in memory and uses a rule engine to execute business rules dependent on the device data. New implementations may be added in the future like database based state manager, multiple samples state managers…\n",
    "description": "",
    "tags": null,
    "title": "State Manager",
    "uri": "/layers/statemanager/index.html"
  },
  {
    "content": " Module Group Module / Bundle Dependencies Comms MQTT Core Commons Connectors Coap Core Commons AT Server Connectors DNP3 Core Commons Connectors HTTP Core Commons Connectors IEC104 Core Commons Connectors MQTT Core Commons MQTT Comms Connectors Websocket Core Commons Core Commons Datastream ADC Core Commons Datastream Device Info Core Commons Datastream Device Info FX30 Core Commons Datastream GPIO Core Commons Datastream I2C Core Commons Event API Datastream ModBus Core Commons Datastream MQTT Core Commons MQTT Comms Datastream Simulador Core Commons Dispatchers OpenGate Core Commons Operation API Event API Dispatchers SCADA Core Commons Events Events API Core Commons Hardware AT Server Core Commons Hardware Comms Core Commons Hardware DioZero Core Commons Hardware I2C Core Commons Hardware JDKDIO Core Commons Hardware ModBus Core Commons Operations API Core Commons Operations Get Core Commons Operation API Operations Discovery Core Commons Operation API MQTT Comms Operations Refresh Info Core Commons Operation API Operations Set Core Commons Operation API Operations Set Clock Core Commons Operation API Operations Sync Clock Core Commons Operation API Operations Update Core Commons Operation API Rule Engine API Core Commons Event API Rule Engine Nashorn Core Commons Event API Rule Engine API Services CBOR Serializer Core Commons Services JSON Serializer Core Commons State Manager In Memory Core Commons Event API Rule Engine API State Manager Real Time Core Commons Event API Subsystem Collector Core Commons Event API Subsystem Poller Core Commons Subsystem SSH Server Core Commons ",
    "description": "",
    "tags": null,
    "title": "Depedency table",
    "uri": "/guides/dependency-table/index.html"
  },
  {
    "content": "Introduction This section will include guides to execute common tasks in ODA development.\nDependencies Some bundles need others to work correctly, because those bundles implements a common api and implements some functions that the first bundles need to use in its operation.\nIt is important to handle the dependencies, including those bundles that need the modules we will use.\nIf you need to know what dependencies have a module that you want to use, you can go to its respective documentation page or use this table.\nDemos The demos are examples of a deploy of ODA.\nDemos are composed by:\nAn assembly directory, with a file in xml format that contains what bundles will be included in the demo. This bundles are the basic resources of apache and logging and the ODA bundles, which contain the functions of the application. A resources bundle that contains all the config files, either of the oda or of the apache and gogo console. Also contains the script that will run the ODA. To use them, you have to run the command\nmvn clean install to generate the tar with everything installed. This tar will have a name with the following format\n\u003cname of the demo\u003e-\u003cversion of the demo\u003e.tar.bz2 Extract the tar and, if you use a device, move the directory extracted to the device. Change the current directory to the demo directory and enter the command:\n./bin/run.sh :::tip If you’re running the demo into OWA450, is important run this as su. To do it, run the command with sudo. :::\nProvided demos Actually are three provided demos by us that the new users of ODA can use to test.\nThese demos can be extended, adapted and used as a base to make your own demo thanks to the modularity of the ODA components.\nCOAP Demo This demo contains the required modules to enable the communication through CoAP, use simulated data streams, handle operations, handle event and communicate with the OpenGate platform.\nThis demo can run in any platform just changing the device info module to the specific device info module of it device.\nYou can see the implementation in our repository\nMQTT Demo This demo contains the required modules to enable the communication through MQTT with Opengate, use simulated data streams, handle operations and handle event. Also use the In Memory State Manager, that will store values of the events into a state instead of send it, receiving the stored data when we do a get.\nThis demo can run in any platform just changing the device info module to the specific device info module of it device.\nYou can see the implementation in our repository\nFX30 MQTT Demo This demo contains the required modules to enable the communication through MQTT with Opengate, use simulated data streams, handle operations and handle event.\nThis demo can run in any platform just changing the device info module to the specific device info module of it device.\nYou can see the implementation in our repository\nCustom demos For made your own demo, you have to create the next things:\nassembly/xxxxx.xml: This is a file with the same format as a pom.xml that specify the name of the demo and the deploy steps of the demo with the bundles used in the demo. resources/apacheFelixConfiguration/config.properties: Framework configuration file. resources/apacheFelixConfiguration/logback.xml: Logger configuration file. Specifies how and where (in which file it is stored) the log information have to be stored. resources/gogoConsoleConfiguration/gosh_profile: Specifies what the console has to write to interact with the user. resources/gogoConsoleConfiguration/motd: Nothing inside this. resources/gogoConsoleConfiguration/motd_remote: Initial output of the demo in the console. resources/gogoConsoleConfiguration/ssh_profile: Specifies what the console has to write to interact with the user if the demo is run through ssh. resources/odaBundlesConfiguration/*: The configuration files of the bundles. These files have to be named as is specified in its documentation page, in the configuration section. resources/scripts/run.sh: This is the bash script that have to run the ODA application. :::tip It is advisable to use a provided demo as base for the custom demo. This is because use existing configuration files, run script and assembly file is easier than made it from scratch. Instead of create a new file of assembly, change the bundles included in the dependencySet of the deploy directory to the desired bundles, putting a include section for each bundle included. If a bundle is removed from the assembly file, delete the configuration file of that bundle and, if it is added, add its configuration file as is explained in the configuration section of its documentation page. :::\nIn order to choose the bundles that will make up the ODA application it’s important to know the dependencies of the bundles that we want to use. The dependencies are listed in the Dependencies section of the documentation page of the desired bundle. A bundle won’t work if its dependencies are not included in the demo.\nDevices Some bundles have many versions depending on the device where the bundle will be run. That is because the libraries implemented use native code and is require to cross-compile the bundle with the right cross-tools. This bundles are, at this moment:\nDNP3 Connector ADC Hardware GPIO Hardware To make it work, you have to install the oda-external-dependencies. To do that, you must have installed the cross-tool of the target device and run the install-oda-external-dependencies:\n./install-oda-external-dependencies.sh x86_64 Linux system To work in your local x86_64 system is not required any installation of a specific cross-tool. Just run the command of external dependencies and deploy the ODA application.\nFX30 To work in a FX30 device, you must have installed Legato on your computer and put the legato directory on your home directory.\nTo install the legato application and its cross tool, download its official IDE.\n:::tip Remember to extract the content of the downloaded zip in the directory $HOME/legato or you will have to change the path used in the external dependencies pom’s to locate the legato cross-tools. :::\nOWA450 To work in a OWA device, you must have installed a ng cross-tool on your computer and put it in /opt directory with the name /opt/gcc-linaro-5.3-2016.02-x86_64_arm-linux-gnueabihf.\nTo install a ng cross tool follow the next steps:\nDownload the cross tool with the command: wget http://crosstool-ng.org/download/crosstool-ng/crosstool-ng-1.23.0.tar.bz2. Create a directory called gcc-linaro-5.3-2016.02-x86_64_arm-linux-gnueabihf in /opt. Extract the downloaded tar in the directory. If any command of the download is missed, you will have to install it, doing an apt-get install \\\u003cname of the command\u003e. This commands are usually gperf, bison, flex, texinfo and help2man.\nIf an error which contains “lib curses” occurs you have to do an apt-get install libncurses-dev.\nFunctions MQTT Communication There are several bundles about the MQTT communication and can be a little confusing understand how to use them. For this reason, we have created this guide. To explain what is the point of each bundle and how to deploy it.\nMQTT Communications This is a kind of interface to the MQTT functionality bundles.\nProvides of various interfaces that the MQTT bundles will use and implements to achieve the connection with the remote MQTT broker and the minimum implemented common classes to handle the MQTT local clients that use the functions and classes of the ODA’s MQTT library.\nThe main end of this module is collect all the uses of the MQTT library in one module as hardware modules do with their respective libraries.\nThe library that implements ODA to handle the MQTT connection is the eclipse paho.\nTo add this bundle to the ODA application is not needed another MQTT bundle, but it’s necessary (like with the most part of ODA bundles) to add the Core Commons. That is because the core commons provides some enums that this module uses.\nMQTT Connector This connector allow to connect with the third system platform (e.g. SCADA or OpenGate) in order to send to it the collected data and allow to receive and respond the operation that these platforms can send to ODA.\nThis module doesn’t uses the paho library but requires that the MQTT Comms bundle has been added to the ODA. In addition to this, requires the Core Commons. That is because the core commons provides the same enums that uses the MQTT Comms, some interfaces and proxies of other dependencies that this module have and some utils.\nMQTT Data stream This data stream allow to connect with another device through MQTT and use its registered data streams. To do this, ODA have to connect to the same broker that the device, ask it for its registered data streams, enable the data streams that the device provides to ODA and, when this is done, made the desired operations about the data streams controlled by this device. To do the operations on the remote device’s data streams, the connection have to be still alive. To know if is alive or not, the device should have a Last Will Message accorded with the broker that will sent to the ODA if the connection of the device is dropped to disable the data streams in ODA and the device itself have to send a similar message if disconnect correctly.\nThat messages will have a topic specific to its message type, sending the Last Will messages through one topic, enabling data streams messages through another, disabling data streams messages by another…\nThis module doesn’t uses the paho library but requires that the MQTT Comms bundle has been added to the ODA. In addition to this, requires the Core Commons. That is because the core commons provides the same enums that uses the MQTT Comms, some interfaces and proxies of other dependencies that this module have and some utils.\nInputs and Outputs There are several ways to receive the in/output of the devices handled by the ODA. The most frequent services are the ADC and DIO, these items are hardware implementation of two different libraries that allow to read and write Analog and Digital in/outputs respectively. Also exists the I2C protocol that is used to communicate between different parts of the same device (sensors, expansion cards, etc.).\nDigital In/Outputs The Digital Inputs Outputs (DIO) hardware module is an implementation of the OpenJDK library.\nThis Hardware Module allows to read the data from the Digital Inputs and write to digital Outputs.\nThis module requires that the device that contains it implements the Sysfs Interface, which is what this module will use. In case of not been implemented, it can’t be used unless we implement an adapter service that will always run since the boot of the device. This adapter is implemented in our repository for the OWA450 device.\nIf the kernel of the device is over 4.4 is probably that the gpio directory and the un/export command doesn’t work. In that case the directory /sys/class/gpio have to be created with two files in it, the export file that will create the digital pin controller if the command echo X \u003e export is run (where X is the number of the pin) and the unexport file that will remove the digital pin controller if the command echo X \u003e unexport is run (where X is the number of the pin).\nIt is important configure the pin with the desired properties for the target pin. To do this, we have a module configuration where, unlike the most of modules, specifies multiple configurations in one file. For each line of the configuration file, we are specifying the configuration of one pin that we want the ODA to handle. This configuration is individual to each pin and will have the next format:\nnumberOfTheConfiguredPin=property1:value1,property2:value2,... numberOfAnotherConfigurePin=property1:anotherValue1,property2:anotherValue2,... For more details to use this module, go to its documentation page\nAnalog In/Outputs The Analog to Digital Converter (ADC) hardware module is an implementation of the DIOZero library.\nThis Hardware Module allows to read the data from Analog Inputs (only for input data).\nThis module requires that the device firmware handle the input analog data and to keep it in a specific file. If the firmware doesn’t keep the data to any file, an adapter has to be created. The adapter, that should be running constantly since boot, has to get the data from the device and keep it in a file. The OWA450 needs an adapter already implemented in our repository.\nOnce we have the file with the data stored in it, the module can read the data from the file configuring it. This module’s configuration, unlike the most of modules, specifies multiple configurations in one file. For each line of the configuration file, we are specifying the configuration of one channel that we want the ODA to handle. This configuration is individual to each channel and will have the next format:\nnumberOfTheConfiguredChannel=property1:value1,property2:value2,... numberOfAnotherConfigureChannel=property1:anotherValue1,property2:anotherValue2,... For more details to use this module, go to its documentation page\nI2C Protocol The I2C module is an implementation of the DIOZero library.\nThis Hardware Module allows to read data from the circuits, sensors, expansion cards, etc. connected to the device that handle the ODA.\nThe configuration of this module, like the rest of I/O Controllers modules, specifies multiple configurations in one file. For each line of the configuration file, we are specifying the configuration of one device that we want the ODA to handle. This configuration is individual to each device and will have the next format:\nnameOfTheConfiguredChannel=property1:value1,property2:value2,... nameOfAnotherConfigureChannel=property1:anotherValue1,property2:anotherValue2,... For more details to use this module, go to its documentation page\nOperations All the operations implements an common API that have to be included in the ODA to run the operations. Each operation module implements the functionality of an operation. The demos have included all operations available on ODA and this is recommended, but in some cases maybe some operation wont be expected and it’s not necessary to include it to ODA.\nThis operations work as follows:\nThe third system send a operation message, serialized in JSON format, to whatever ODA’s connector. ODA’s connector pass the message to the dispatcher The dispatcher deserialize the message. The dispatcher get the operation code and search for implementation of that in its current catalogue. The dispatcher run the implementation’s process method. The implementation of the operation processes the arrived information from the connector. The operation returns a Result message that will be returned serialized to the connector. Connector send the response message (AKA payload). If you need to do tests with the operations is highly recommended to use the MQTT connector and the Mosquitto application. This application mock a MQTT broker and allow to send messages / put listeners on that broker, so we can to enter manually the operations messages that the ODA expects to do the operation.\nThis messages can be found in the Trace section of each documentation page of the Operations\nCustom Operation To create your own operation, you have to implement the Custom Operation Interface. It’s important that the third system can send the operation request that ODA expects and the specific format.\nState Manager There are currently two implementations of the dispatcher module.\nReal Time Dispatcher: Dispatcher that doesn’t store any data in itself. All the incoming data will be sent directly. In Memory Dispatcher: Dispatcher that stores the incoming information to cna send it by request or handle derived information. To use the dispatchers, is necessary to include in the demo the dispatcher API, that contains the commons dispatcher functions.\nReal Time State Manager To deploy this dispatcher is important to use the Dispatcher API.\nNothing else is needed.\nIn Memory State Manager To deploy this dispatcher you have to deploy the Dispatcher API, the Rule Engine API and the specific implementation of the rule engine that you will use.\nThis is because the historic data will be used by the rule engine bundle and is needed to include it to be used, having both of these bundles a mutual dependency.\n",
    "description": "",
    "tags": null,
    "title": "Guides",
    "uri": "/guides/index.html"
  },
  {
    "content": "ODA has an update operation that allows to install or update software, rules or configuration in ODA from a third system.\nWe must configure the parameters needed for this operation in file es.amplia.oda.operation.update.cfg. It will take five parameters:\nrulesPath - path of the folder where rules will be installed (rules/)\nrulesUtilsPath - path of the folder where auxiliary javascript files to use with rules will be installed (jslib/)\nbackupPath - path of the folder where backups will be made (backup/)\ndeployPath - path of the folder where bundles will be deployed (deploy/)\ndownloadsPath - path of the folder where new software or rule will be downloaded before install (downloads/)\nconfigurationPath - path of the folder where configuration will be installed (configuration/)\n",
    "description": "",
    "tags": null,
    "title": "New Software",
    "uri": "/scenarios/updatesoftware/index.html"
  },
  {
    "content": "Read data from an IEC104 device ODA allows to read data from an IEC104 device using these bundles:\nes.amplia.oda.datastreams.iec104 es.amplia.oda.comms.iec104 es.amplia.oda.service.scadatables We will explain how to configure these bundles to connect to the device and to read data from it.\nThe first step is to configure the connection with the device. This is defined in the configuration of datastreams bundle (es.amplia.oda.datastreams.iec104.cfg):\npollingTime=10000 iec104DeviceId=127.0.0.1;2404;1 The pollingTime parameter indicates the seconds between executions of Interrogation Commands. Every x seconds, an Interrogation Command is sent to the devices defined in the configuration. When the IEC104 device receives the interrogation command, it sends all the data it has stored to ODA and stores it in a cache.\nThe next lines of the configuration indicates the information needed to connect with the IEC104 devices. The first element is the deviceId that will be associated to the data retrieved. The second and third elements are the ip address and port of the IEC104 device. The last element indicates the commonAddress, it identifies the IEC104 device in the network.\nOnce we have the connection with the devices defined, we have to define the data we want to retrieve. This is defined in the ScadaTable bundle (es.amplia.oda.service.scadatables.cfg) with the format:\nM_ME_NC_1,106001 = datastream: tensFaseFaseLA01 M_SP_NA_1,101040 = datastream: estProtLA01 M_DP_NA_1,104700 = datastream: estReenganCF11 M_BO_NA_1,110000 = datastream: identCCPLO M_ST_NA_1,107001 = datastream: limPosTR01 Every line represents an element read from the IEC104 device. The format is :\nASDU, address = datastream: datastreamId The ASDU indicates the type of the value read.\nThe address indicates the address where the value is stored in the IEC104 device.\nThe datastreamId indicates the Id of the datastream assigned to the value read.\nODA supports the next ASDUs:\nM_SP_NA_1 = Single Point M_DP_NA_1 = Double Point M_ME_NC_1 = Measured Float M_ST_NA_1 = Step Position M_BO_NA_1 = Bitstring M_ME_NA_1 = Measured Normalized M_ME_ND_1 = Measured Normalized (no quality information) M_ME_NB_1 = Measured Scaled With the IEC104 protocol configured, the last step is to configure poller bundle to retrieve the data from the IEC104 cache. When the poller launches its operation, it retrieves the data indicated from the IEC104 cache and stores it in the StateManager. Once the poller retrieves the data from the cache, it follows the same path trough ODA bundles as other data until it is published.\n",
    "description": "",
    "tags": null,
    "title": "Read data from IEC104 devices",
    "uri": "/scenarios/readdataiec104/index.html"
  },
  {
    "content": "Rule Engine The rule engine executes custom business rules dependent on the device data. The rules may be deployed from our OpenGate IOT Platform and are loaded at runtime.\nThe rules are based in a when -\u003e then paradigm:\nwhen: Predicates defining when the rule should be executed then: Actions to execute when the predicates evaluates to true. The scope available inside this functions includes the state of the device (all the values of the datastreams in the current moment) and the new value that has triggered the rules evaluation.\nThe interface of a rule is defined as:\npublic interface Rule { boolean when(State state, DatastreamValue newValue); State then(State state, DatastreamValue newValue); } Implementation Nashorn Rule Engine The main implementation of the Rule Engine has been developed using Nashorn engine, allowing to easily define the business rules using JavaScript.\nThe rules are written in JavaScript and deployed in the device to be registered.\nEvery time an event is triggered inside the device with a datastream value update, all the registered rules are triggered to take the necessary actions.\nA catalogue of actions is provided to ease the rule definitions.\nAlternative implementations New implementations may be added in the future implementing the RuleEngine interface:\npublic interface RuleEngine { State engine(State state, DatastreamValue value); void createDatastreamDirectory(String nameRule); void deleteDatastreamDirectory(String nameRule); void createRule(String nameRule); void deleteRule(String nameRule); void reloadAllRules(); void stop(); } ",
    "description": "",
    "tags": null,
    "title": "Rule Engine",
    "uri": "/layers/ruleengine/index.html"
  },
  {
    "content": "The Subsystems multi-module contains modules providing complete features that were needed and runs independently of the rest of the system.\nPoller The Poller subsystem is responsible for polling datastream getters to update the State Manager, preventing outdated data.\nConfiguration The Poller subsystem configuration is provided in a configuration file with the following line format:\ndatastreamId;deviceId=firstPollingInSeconds;nextPollingInSeconds The configuration fields are:\ndatastreamId: Datastream identifier to poll deviceId: Device identifier to poll. If no one is provided all devices are polled. Optional firstPollingInSeconds: Seconds to poll for the first time. Optional nextPollingInSeconds: Period between polls. Could be 0 to poll just one time. Collector The Collector subsystem is responsible for collecting datastream data from the State Manager to send it to the Dispatcher (so it goes to the connector and is sent to the Internet).\nConfiguration The Collector subsystem configuration is provided in a configuration file with the following line format:\ndatastreamId;deviceId=firstCollectingInSeconds;nextCollectingInSeconds The configuration fields are:\ndatastreamId: Datastream identifier to collect deviceId: Device identifier to collect. If no one is provided the datastreams of all devices are collected. Optional firstCollectingInSeconds: Seconds to collect for the first time. Optional nextCollectingInSeconds: Period between collects. Could be 0 to collect just one time. SSH Server The SSH server subsystems provide a SSH server to connect to the ODA console (based in Apache Felix Gogo).\nConfiguration The configuration is:\nip: Ip address where the server is listening port: Port where the server is listening. username: Username to authorize the connection. password: Encoded password using SHA-512 to authorize the connection. A configuration file example is\nip=127.0.0.1 port=50000 username=oda password=0d878278b5225ed381a8b4114acca68e019dfb346f1d067271137abcdaaa46200b6b7e0d459ccf821aa788216fd8ca6168f6c814505d64fc5cdb5fdecedbdc2f # oda ",
    "description": "",
    "tags": null,
    "title": "Subsystems",
    "uri": "/infrastructure/subsystems/index.html"
  },
  {
    "content": "Here we are going to see how we can develop new features for ODA.\nRecollect data from new devices\nBundle configuration\nCreate new operation\n",
    "description": "",
    "tags": null,
    "title": "Develop",
    "uri": "/develop/index.html"
  },
  {
    "content": "Operations The operation layer contains operations that can be executed by the device.\nThis operations have to be sent to the device by the third system.\nThe API module has the basic operation definitions and the custom operations interface.\nBasic Operations The basic operations are:\nRefresh Info: Send the values of the datastreams at the moment the operation is received. Get Device Parameters: Get the values of the specified datastreams at the moment the operation is received. Set Device Parameters: Set the given values in the specified datastreams. Set Clock: Set the clock of the specified device with the given timestamp. Synchronize Clock: Synchronize the clock of the specified device with the given source. Discover: Send a discovery command to all devices in the LAN network to register themselves. Update: Make a software or configuration update in the device. Custom Operations The CustomOperation interface allows to add operation specific to project needs easily, without modifying the operations api modules and operation dispatcher.\npublic interface CustomOperation { CompletableFuture\u003cResult\u003e execute(String deviceId, Map\u003cString, Object\u003e params); String getOperationSatisfied(); } To implement a custom operation you should deploy a new OSGi bundle with a registered service implementing the execute method. Usually, this method should extract the operation params from the params generic map, execute the operation and return a result object with all the necessary information about the operation execution. It also has to define which operation is responsible for through the getOperationSatisfied method.\nIt’s important to implement the operation knowing that the params (parameters) of the operation will be an array of objects with two values:\nname: name of the parameter value: value of the parameter The JSON message that the third platform will send to ODA to do a custom operation will be a format like this:\n{ \"operation\": { \"request\": { \"timestamp\": \"\u003ctimestampOfTheSendingOperation\u003e\", \"deviceId\": \"\u003cdeviceOfTheTarget\u003e\", \"name\": \"\u003cnameOfTheOperation\u003e\", \"parameters\": [{ \"name\": \"parameter1\", \"value\": \"value1\" }, { \"name\": \"parameter2\", \"value\": \"value2\" }], \"id\": \"\u003cidOfTheOperation\u003e\" } } } ",
    "description": "",
    "tags": null,
    "title": "Operations",
    "uri": "/layers/operations/index.html"
  },
  {
    "content": "Event Dispatcher The event dispatcher is responsible for receiving the events generated in the device and sending them through the available connectors.\nThe interface defining the service is the EventDispatcher interface and the main method is the publish method that receives an event:\npublic interface EventDispatcher { void publish(Event event); } Events objects are explained in the Events page.\nOpenGate Event Dispatcher The OpenGate Event Dispatcher publishes the received events through an OpenGate connector with the OpenGate IOT JSON format.\nThe publish method use the proper serializer to serialize the received event to the configured content-type and send it to the active OpenGate Connector.\nDependencies Serializers: Any needed implementation of Serializer Service that the dispatcher will need to de/serialize the payloads. Device Info Provider: Needed to know the Device Id of the device that are running the Agent and the API Key to access to OpenGate. OpenGate Connector: Needed to send data and respond to requests of OpenGate. Configuration The Event Dispatcher can be configured with the following global properties:\nreducedOutput: Use a reduced IOT format, removing all optional fields, to decrease the bandwidth consumed. The default value is false eventContentType: Content-type of the published events. The default content-type format is JSON. Using a decorator pattern, the Event Collector allows to store the events of some configured datastreams to send multiple datapoints in the same message at a configured period of time. Each datastream is configured in a line in the configuration file with the following format:\ndatastreamId;deviceId=initialDelay;period The configuration is built with the properties:\ndatastreamId: Datastream identifier configured. deviceId: Device identifier configured. If not set, the current configuration is applied to all devices. Optional initialDelay: First time the collected events are sent. Optional period: Period in which the collected events are sent. May be 0 to configure a datastream that must be sent just one time when ODA starts. An example of a valid configuration may be:\nreducedOutput=true # Use reduce output eventContentType=JSON # Use JSON format content-type device.software=30;0 # Send all devices software 30 seconds after start-up and do not sending again device.temperature.value=60 # Send all devices temperatures every 60 seconds current;sectionalizer123=30;300 # Send the sectionalizer123 current 30 seconds after start-up and every 5 minutes. ",
    "description": "",
    "tags": null,
    "title": "Event Dispatcher",
    "uri": "/layers/eventdispatcher/index.html"
  },
  {
    "content": "Operation Dispatchers The operation dispatchers are responsible for getting the high level operation requests from the low level representation, pass them to the proper operation processor and send back the responses to the connector as low level representation also.\nThis components should also take care of the operation error handling: serialization errors, error in operation params, not supported operations…\nThe entry point is the process method getting the requests and returning the response.\nOpenGate Dispatcher The OpenGate Dispatcher takes care of the OpenGate operation requests. It implements the Dispatcher interface:\npublic interface Dispatcher { CompletableFuture\u003cbyte[]\u003e process(byte[] input, ContentType contentType); } The process method gets the request byte array and content-type and returns the response byte array. It is assumed that the response content-type is the same as the request. If no content-type is provided, JSON format is taken by default.\nThe component deserialize the request and send it to the correct operation processor to be processed. Then receives the OpenGate Operation response, serialize it and send it back to the connector. It handles the errors about serialization, format and not supported operations.\nTo create the operation processors it uses a factory with the OpenGate already supported operations. This is the entry point to add new operations using the OperationProcessorTemplate. The operation API should be defined in the Operations API module.\nThe OpenGate Operation Dispatcher also provides a feature to handle custom operations that allows to add new operations without modifying the OpenGate Operation Dispatcher and the Operations API. They must implement the CustomOperation and define the operation name they handle:\npublic interface CustomOperation { CompletableFuture\u003cResult\u003e execute(String deviceId, Map\u003cString, Object\u003e params); String getOperationSatisfied(); } SCADA Dispatcher The SCADA Dispatcher takes care of the SCADA operation requests. It implements the SCADA Dispatcher:\npublic interface ScadaDispatcher { \u003cT, S\u003e CompletableFuture\u003cScadaOperationResult\u003e process(ScadaOperation operation, int index, T value, S type); } It processes a SCADA operation on a given index, value and type and returns a ScadaOperationResult:\nenum ScadaOperationResult { SUCCESS, ERROR, NOT_SUPPORTED } ",
    "description": "",
    "tags": null,
    "title": "Operation Dispatchers",
    "uri": "/layers/operationdispatcher/index.html"
  },
  {
    "content": "Datastream format We can see the format of the datastreams used by ODA in this link\nOpenGate IOT JSON\nDefinition of state The State is the collection of datastreams managed in a moment by ODA.\nChange state manager mode To change the way state manager works we must change the state manager bundles deployed.\nTo work in real time mode, use the bundle statemanager.realtime\nTo work in memory mode, use the bundle statemanager.inmemory\nIf there is both realtime and inmemory bundles deployed, remove the one which isn’t being used.\nChanges in bundle configuration files If ODA is running, changes made in bundle configuration files are loaded instantly, there is no need to stop and launch ODA again.\nLoad or remove new bundles from ODA To load a new bundle in ODA, we just need to copy the jar containing the bundle in the deploy directory. ODA will detect it and try to start the new bundle calling its start method.\nIf we want to remove a bundle already deployed, simply remove the jar file from deploy directory. ODA will call bundle stop method and remove it from the framework.\nView ODA logs ODA writes its logs in the file ODA.log located in ODA/logs/.\nIn this file we can see the logs of current day.\nTo view the logs of previous days, ODA stores them in ODA/logs/archived.\n",
    "description": "",
    "tags": null,
    "title": "FAQs",
    "uri": "/guides/faqs/index.html"
  },
  {
    "content": "Other In this section we explain bundles that are not part of any of the main sections but are needed in certain scenarios.\n",
    "description": "",
    "tags": null,
    "title": "Other",
    "uri": "/layers/other/index.html"
  },
  {
    "content": "ADC This Datastream module enable to register the datastreams of Diozero Hardware module.\nThis datastreams corresponds to the Analog Input Pins of the device.\nTo access source code click here.\nDependencies This module requires the following modules:\nDio Zero: Provide an implementation of ADC Service that the datastream module need to provide information of each datastream. Event Publisher: Used to handle the incoming events and send it. Configuration To configure ADC Datastream module, a file named es.amplia.oda.datastreams.adc.cfg must be created with the next parameters for each input channel that you want to register:\nchannelPin: -1 by default. Specify the identifier of the Analog input channel. getter: true by default. Enable the option to use this channel as datastream getter (have to check the value manually every time that want to know actual value). event: false by default. Enable the option to use this channel as datastream event (automatically will send the to the Event Handlers when a event is generated). min: 0.0 by default. Specifies the value that datastream will take when the hardware channel value is in the minimum of the range. max: 1.0 by default. Specifies the value that datastream will take when the hardware channel value is in the maximum of the range. es.amplia.oda.datastreams.adc.cfg will have a similar format to:\n1=getter:true,event:true,min:0,max:10 2=getter:true,event:false,min:1,max:18 3=getter:false,event:true,min:-10,max:40 4=getter:false,event:false,min:0,max:0 ",
    "description": "",
    "tags": null,
    "title": "ADC",
    "uri": "/layers/datastreams/adc/index.html"
  },
  {
    "content": "AT Server This Hardware module allows to mount an AT Server to send AT Commands to an AT client.\nThis module requires of add to the application the AT Manager and AT Server to make it work properly.\nTo access source code of AT Server click here.\nTo access source code of AT Manager click here.\nDependencies This module requires the following modules:\nCommons: Provide the basic APIs to register the service. Configuration To configure I2C Hardware module, a file named es.amplia.oda.hardware.atserver.cfg must be created with the next parameters:\napp-name: Required parameter. Name of the own application that will open the serial port. ms-get-port: Required parameter. Time in ms to achieve the connection with the serial port. If connection is not achieved in time internal port will be null and a Exception will be thrown. port-name: Required parameter. Name of the serial port that module have to use. baud-rate: Required parameter. Baud rate with the connection will be tried. It can be 9600, 38400 and 115200. data-bits: Required parameter. Data bits of the connection with the serial port. It can be 5, 6, 7 and 8. stop-bits: Required parameter. Stop bits of the connection with the serial port. It can be 1 or 2. parity: Required parameter. Parity of the connection with serial port. It can be: ‘N’(one), ‘O’(dd), ‘E’(ven), ‘M’(ark) and ‘S’(pace). timeBetweenCommands: Required parameter. Time that the AT Manager will wait after enter a AT command to the serial port. It’s important put it because es.amplia.oda.hardware.atserver.cfg will have this format:\napp-name=oda-serial ms-get-port=2000 port-name=ttyS0 baud-rate=38400 data-bits=8 parity=N stop-bits=1 ",
    "description": "",
    "tags": null,
    "title": "AT Server",
    "uri": "/layers/hardware/atserver/index.html"
  },
  {
    "content": "Get bundle configuration from file Like ODA bundles, we can make our bundle to get its configuration from a file and to react to changes in this configuration file.\nThe configuration file must have the same name as the java package of our bundle.\nTo achieve this we must create two classes in our code.\nOne class will be the one containing the parameters our bundle needs. In this example our bundle needs two parameters that are two strings.\n@Builder public class WsConfiguration() { String measureUrl; } The other class will implement the interface ConfigurationUpdateHandler which will have two methods:\nloadConfiguration - this method retrieves the values of the variables defined in configuration file public void loadConfiguration(Dictionary\u003cString, ?\u003e props){ String measureUrl = (String) props.get(\"measureUrl\"); config = WsConfiguration.builder().measureUrl(measureUrl).build(); } applyConfiguration - this method applies the changes in configuration detected. To do this it calls the methods defined in our bundle classes to reload configuration to use new values. public void applyConfiguration() { measureGetter.loadConfiguration(config); } ",
    "description": "",
    "tags": null,
    "title": "Bundle configuration",
    "uri": "/develop/bundleconfiguration/index.html"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "Categories",
    "uri": "/categories/index.html"
  },
  {
    "content": "This connector enables communication via CoAP Protocol.\nOnly allows to send data to the OpenGate platform. Operations can’t be received.\nDependencies This module requires the following modules:\nCore Commons: Provides many interfaces that this module will use. Device Info Provider: Needed to know the Device Id of the device that are running the Agent, and the API Key to access to OpenGate. Both data are required to achieve a connection with OpenGate and transferred data will have the deviceId in its metadata. AT Server: If connector is configured as AT type connector, this is necessary to use AT commands in the connector. Configuration To configure CoAP connector, a file named es.amplia.oda.connector.coap.cfg must be created with the next parameters:\ntype: UDP Connector by default. The available options are: UDP, DTLS, AT. Specify the type of connector that CoAP connector will be. host: Required data. Specify the direction of the third system the connector have to send the data. port: Automatically search a default. Port though the connector have to connect to the host. path: Required data. Main section of the URI where the connector have to handle the data. provisionPath: Required data. Last section of the URI. timeout: 30 by default. Time connector will wait to achieve the connection. messageProtocolVersion: 1.0.0 by default. Version of the protocol used to send the data. localPort: 4123 by default. Port Of th current device where the connector will connect. keyStoreType: “JKS” by default. Is the type of the KeyStore that the connector will use. keyStoreLocation: null if not specified, Required if connector type is DTLS. Directory where the file of keys will be stored. keyStorePassword: null if not specified, Required if connector type is DTLS. Password to access to the KeyStore. clientKeyAlias: “client” by default. Alias used to find in KeyStore and TrustStore the key needed to connect. trustStoreType: “JKS” by default. Is the type of the TrustStore that the connector will use. trustStoreLocation: null if not specified, Required if connector type is DTLS. Directory where the file of keys will be stored. trustStorePassword: null if not specified, Required if connector type is DTLS. Password to access to the TrustStore. trustedCertificates: null if not specified, Required if connector type is DTLS. Names of certificates separated by commas. The file es.amplia.oda.connector.coap.cfg can have several formats:\ntype=UDP host=localhost path=v80/devices provisionPath=collect/iot type=DTLS host=localhost path=v80/devices provisionPath=collect/iot keyStoreLocation=path/to/keyStore keyStorePassword=passToAccess trustStoreLocation=path/to/trustStore trustStorePassword=passToAccess trustedCertificates=certificates,separated,by,commas type=AT host=localhost path=v80/devices provisionPath=collect/iot Source Code You can check the source code here\n",
    "description": "",
    "tags": null,
    "title": "COAP",
    "uri": "/layers/connectors/coap/index.html"
  },
  {
    "content": "Comms This Hardware module allow ODA to connect to the Internet with a GSM connection. This connection requires of a device with a SIM card connect to it. This module is currently only made to work in Sierra Wireless FX30/FX30S devices. To extend this module is as easy as create new scripts that works for the desired device.\nTo access source code click here.\nDependencies Commons: Provide the basic APIs to register the service. Configuration To configure Comms Hardware module, a file named es.amplia.oda.hardware.comms.cfg must be created with the next parameters\npin: \"\" (void String) by default. This is the PIN Code of the inserted SIM card. apn: Required parameter. This is the APN where the SIM card will connect to get the information to achieve a connection to wireless network. username: \"\" (void String) by default. The user to access to the APN. password: \"\" (void String) by default. The pass to access to the APN. connectionTimeout: 60 by default. Time (in seconds) that the module will wait before to do a timeout if network delay in response. retryConnectionTimer: 60 by default. Time (in seconds) that the module will wait after try to connecting to try it again. es.amplia.oda.hardware.comms.cfg will have a similar format to:\npin=1234 apn=telefonica.es username=telefonica password=telefonica connectionTimeout=15 retryConnectionTimer=30 ",
    "description": "",
    "tags": null,
    "title": "Comms",
    "uri": "/layers/hardware/comms/index.html"
  },
  {
    "content": "Request data periodically from devices not supported Using ODA capabilities we can easily implement our solution to retrieve data from a device.\nImplement DatastreamGetter Using ODA capabilities we can easily make a bundle to request data periodically from a device.\nFor our bundle to implement this functionaility we must create a class that implements DatastreamsGetter. It will have three public methods:\ngetDatastreamIdSatisfied\nreturns the id of the datastream that will be associated with the data collected from this device\ngetDevicesIdManaged\nreturn the list of ids of the devices that we are managing\nget\nthis method will implement the code needed to retrieve data from the device\nThis class we just created must be registered for the framework to know it exists. To achieve this we use the registerService method from BundleContext class:\nbundleContext.registerService(DatastreamsGetter.class, getter, null); Now that the bundle code is complete, we must tell ODA to poll data from device. For this we must write a new line in configuration file es.amplia.oda.subsystem.poller.cfg with the next format:\ndatastreamId;deviceId=firstPollingInSeconds;nextPollingInSeconds;\nWith this line we tell ODA to retrieve data for the device and datastream indicated every x seconds. When x seconds pass, ODA will search in all the DatastreamsGetter registered in the framework, the one that matches the datastream and device indicated. Then it will execute the get method of the DatastreamsGetter that matches, and will format the value retrieved from the device into the datastream format used by OpenGate. The datastream generated with the value retrieved from device will be passed to the state manager.\nConnection with device To request data from the device, ODA needs to know which hardware protocol must be used to communicate with it.\nThis protocol is defined in the configuration files with name like es.amplia.oda.datastreams.* , where * is the name of the protocol to use.\n",
    "description": "",
    "tags": null,
    "title": "DataStream Getter",
    "uri": "/develop/datastreamgetter/index.html"
  },
  {
    "content": "Device Info This Datastream module enable to register the datastreams to provide the information of the device. This means that each device will have its own module Device Info.\nThere are this devices info modules for now:\nx86_64 System devices: Devices with a x86_64 Linux system FX30: Sierra Wireles FX30/FX30S devices OWA450: Owasys OWA450 devices Dependencies This module have no dependencies.\nConfiguration To configure Device Info module, a file named es.amplia.oda.datastreams.deviceinfo.cfg (or deviceinfofx30, or deviceinfoowa450) must be created with the next parameters for each input channel that you want to register:\ndeviceId: (null if not specified). Identifier of the device. This parameter is used by the third-system (OpenGate, Scada…) to identify where the data arrive from. apiKey: (Required parameter). API Key (like a pass) to access to the third-system. source: (Required parameter). Directory where the bundles (.jar’s) are installed. path: (Required parameter). Directory where the script of the Device Info are installed. These files will be executed on runtime to collect the information. es.amplia.oda.datastreams.deviceinfo*.cfg will have a similar format to:\n# Device identifier. If not provided the serial number is used deviceId=testDevice # API Key to connect to OpenGate apiKey=testApiKey # Directory to get the scripts source=deploy # Directory to extract the scripts path=scripts ",
    "description": "",
    "tags": null,
    "title": "Device Info",
    "uri": "/layers/datastreams/deviceinfo/index.html"
  },
  {
    "content": "DIOZero Implementation of the library DIOZero to give an access to analog in/outputs. This is the hardware module that give support to ADC Datastreams.\nTo access source code click here.\nDependencies This module requires the following modules:\nCommons: Provide the ADC APIs, exceptions and types and the basic APIs to register the service. Configuration To configure I2C Hardware module, a file named es.amplia.oda.hardware.diozero.cfg must be created with the next parameters for each input channel that you want to register:\nindex: Required parameter. Index of the channel. deviceType: \"\" (void String) by default. Type of this pin. adc.ADCChannel for specify an analog channel. name: Required parameter. Unique name for the channel. lowMode: Required parameter. Specify if lowMode is enabled. path: Required parameter. Path to the local directory that contains the value of this pin. device: Required parameter. Name of the device that handles this pin (OWASYS, FX30 or anyone else). es.amplia.oda.hardware.diozero.cfg will have a similar format to:\n1=deviceType:adc.ADCChannel,name:light,lowMode:false,min:0,max:10 4=deviceType:adc.ADCChannel,name:temperature,lowMode:false,min:-10,max:50 ",
    "description": "",
    "tags": null,
    "title": "DIOZero",
    "uri": "/layers/hardware/diozero/index.html"
  },
  {
    "content": "Discover This operation is used to send to another MQTT client a request to enable all datastreams provided by the device that owns that client. When the request was processed by the remote device, ODA expects that a message enabling all the datastreams was send by the remote device.\nThis operations will send the request message serialized in CBOR format to a specific topic selected by configuration.\nDependencies Commons: Required to provide the commons utils, the Operation Discover API and the basic APIs to register the service. Operation API: Provides the api of the operation and the enums of the result code. Comms MQTT: Provides the classes to use the mqtt client. Configuration To configure Discover Operation module, a file named es.amplia.oda.operation.discover.cfg must be created with the next parameters:\nbrokerURI:Required parameter. Direction of mqtt broker where the client have to connect. clientId:Random if not specified. Id of the client that the operation will create to do the operation. Must to be different that the MQTT client id of the MQTT connector if it’s present. discoverTopic:Required parameter. Topic where the another MQTT client expects that the discovery request will be sent. Trace The trace send by the third system (e.g. OpenGate) to the ODA to do this operation is like this:\n‘{“operation”:{“request”:{“timestamp”:1557306193823,“deviceId”:“aDevice”,“name”:“DISCOVER”,“parameters”:[],“id”:“73da9ff8-15a9-4e9a-9b2d-b6e5efbc856b”}}}’\n",
    "description": "",
    "tags": null,
    "title": "Discover",
    "uri": "/layers/operations/discover/index.html"
  },
  {
    "content": "This connector enables communication via DNP3 Protocol.\nAllow the transfer of data and operations with an SCADA third-system that implements an DNP3 master (client).\nDependencies This module requires the following modules:\nScada Table Info: Needed to serve to the connector the information of inputs, outputs and counters and can create a DB with them. Scada Dispatcher: Needed to process the payloads and de/serialize its content. Core Commons: Provides many interfaces that this module will use. Configuration To configure DNP3 connector, a file named es.amplia.oda.connector.dnp3.cfg must be created with the next parameters:\nchannelIdentifier: “tcpServerChannel” by default. A unique name of the channel to which the connector will be connected. outstationIdentifier: “outstation” by default. A unique name of the connector inside the channel. ipAddress: “0.0.0.0” by default. IP direction of the allowed incoming messages through the channel. 0.0.0.0 allows that all the directions could send messages to the connector. Is the way to specify from where can be sent messages in case of only one sender. ipPort: 20000 by default. Port though the connector have to connect to the host. localDeviceDnpAddress: 1 by default. Direction of the own connector. remoteDeviceDnpAddress: 1024 by default. Direction of the device from the connector will receive messages. unsolicitedResponse: false by default. Enable / disable the option to send unsolicited messages. eventBufferSize: 5 by default. Specify the number of events that can be buffered on the local connector before overflowing. logLevel: NORMAL default. The available options are 0 (No log), 15 (Normal log), 30720 (APP_COMMS log), 65535 (All log). In other words, es.amplia.oda.connector.dnp3.cfg can will have the content:\nchannelIdentifier=channelIdentifier outstationIdentifier=connectorIdentifier ipAddress=0.0.0.0 ipPort=20000 localDeviceDnpAddress=1 remoteDeviceDnpAddress=1024 unsolicitedResponse=false eventBufferSize=10 logLevel=0 It can work without anything inside the configuration file except the data you want different from the default.\nSource Code You can check the source code here\n",
    "description": "",
    "tags": null,
    "title": "DNP3",
    "uri": "/layers/connectors/dnp3/index.html"
  },
  {
    "content": "Events ODA internal events are objects created with the value tag of Lombok.\nThis internal objects are created to notify a new value to the state manager and are handled by the state manager or the rule engine, depending on the state manager implementation that we will use.\nThe event object will have the next parameters to specify the information of the event.\nThe Event is defined as:\npublic class Event { private String datastreamId; private String deviceId; private String[] path; private Long at; private Object value; } Datastream ID is the id of the datastream which has changed and created an event to notify that change to the state manager. Device ID is the id of the device that contains the changed datastream. Path is the way to arrive to the device which contains the datastream. At is the timestamp of the moment the event was created. Value is the new value that the datastream has collected. If a rule engine is included, it is possible that the value saved into the state manager will be different to the arrived value. ",
    "description": "",
    "tags": null,
    "title": "Events",
    "uri": "/layers/eventdispatcher/events/index.html"
  },
  {
    "content": "Get Device Parameters This operation is used to get the actual value of a datastream of the device.\nThe value getted by the operation will be passed to the state manager, which handle it according its implementation.\nDependencies Operation API: Provides the api of the operation and the enums of the result code. State Manager: Provides the API of the State Manager that will handle the returned value by the operation. Trace The trace send by the third system (e.g. OpenGate) to the ODA to do this operation is like this:\n‘{“operation”:{“request”:{“timestamp”:1554978284595,“deviceId”:“6000”,“name”:“GET_DEVICE_PARAMETERS”,“parameters”:[{“name”:“variableList”,“value”:{“array”:[{“variableName”:“current”}]}}],“id”:“4aabb9c6-61ec-43ed-b0e4-dabface44b64”}}}’\n",
    "description": "",
    "tags": null,
    "title": "Get Device Parameters",
    "uri": "/layers/operations/getdeviceparameters/index.html"
  },
  {
    "content": "GPIO This Datastream module enable to register the datastreams of JDK DIO Hardware module.\nThis datastreams corresponds to the Digital Input Pins of the device. This implementation requires the use of the sysfs interface. This means that this module is not supported by kernels older than the version 4.4.\nTo access source code click here.\nDependencies This module requires the following modules:\nJDK DIO: Provide an implementation of GPIO Service that the datastream module need to provide information of each datastream. Event Publisher: Used to handle the incoming events and send it. Configuration To configure GPIO Datastream module, a file named es.amplia.oda.datastreams.gpio.cfg must be created with the next parameters for each input channel that you want to register:\npinIndex: Required parameter. Number of the pin that correspond to the datastream. datastreamId: Required parameter. Identifier name of the datastream. getter: true by default. Enable the option to use this channel as datastream getter (have to check the value manually every time that want to know actual value). setter: true by default if pin is configured as OUTPUT. Enable the option to use this channel as datastream setter (heve to send a operation to change the value of this datastream). event: true by default if pin is configured as INPUT and NONE trigger. Enable the option to use this channel as datastream getter (automatically will send the to the Event Handlers when a event is generated). es.amplia.oda.datastreams.gpio.cfg will have a similar format to:\n## Model of configuration of jdk file # # datastreamId=getter:\u003cgetter\u003e,setter:\u003csetter\u003e,event:\u003cevent\u003e # # getter -\u003e (optional) true / false # setter -\u003e (optional) true / false # event -\u003e (optional) true / false # 4 = datastreamId:gpio4, getter:true, setter:false, event:true 5 = datastreamId:gpio5, getter:false, setter:true, event:false 6 = datastreamId:gpio6, getter:false, setter:true, event:false ",
    "description": "",
    "tags": null,
    "title": "GPIO",
    "uri": "/layers/datastreams/gpio/index.html"
  },
  {
    "content": "HTTP This connector enable communication via HTTP Protocol.\nOnly allows to send data to the OpenGate platform. Operations can’t be received.\nDependencies This module requires the following modules:\nCore Commons: Provides many interfaces that this module will use. Device Info Provider: Needed to know the Device Id of the device that are running the Agent and the API Key to access to OpenGate. Both data are required to achieve a connection with OpenGate and transferred data will have the deviceId in its metadata. Configuration To configure HTTP connector, a file named es.amplia.oda.connector.http.cfg must be created with the next parameters:\nhost: Required parameter. Specify the direction of the third system the connector have to send the data. ’localhost’ is a good host to do tests with. port: 80 by default. Port though the connector have to connect to the host. generalPath: Required parameter. General path of the URL where the connector have to send data. collectionPath: Required parameter. Last section of the URL where the connector have to send data. compressionEnabled: false by default. Specify if the data sending have to be encoded to GZIP to be sent to the third system. compressionThreshold: 512 by default. Specify what size have to has the data sent to third system to be encoded if compressionEnabled is true. The format of URL used to send data is …/‘generalPath’/‘deviceId’‘collectionPath’\nIn other words, es.amplia.oda.connector.http.cfg will have the content:\nhost=localhost port=80 generalPath=commonPathToAllSites collectionPath=/odaData compressionEnabled=true compressionThreshold=0 And can run with the following minimal content:\nhost=localhost generalPath=commonPathToAllSites collectionPath=/odaData Source Code You can check the source code here\n",
    "description": "",
    "tags": null,
    "title": "HTTP",
    "uri": "/layers/connectors/http/index.html"
  },
  {
    "content": "I2C This Datastream module enable to register the datastreams of I2C Hardware module.\nThis datastreams corresponds to the I2C devices connected to the device.\nTo access source code click here.\nDependencies This module requires the following modules:\nI2C Hardware: Provide an implementation of I2C Service that the datastream module need to provide information of each datastream. Configuration To configure I2C Datastream module, a file named es.amplia.oda.datastreams.i2c.cfg must be created with the next parameters for each input channel that you want to register:\nname: Required parameter. Identifier name of the datastream. getter: true by default. Enable the option to use this channel as datastream getter (have to check the value manually every time that want to know actual value). setter: false by default. Enable the option to use this channel as datastream setter (have to send a operation to change the value of this datastream). device: Required parameter. Identifier name of the i2c device hardware min: 0 by default, if min \u003e max then min = 0. Specifies the value that datastream will take when the hardware channel value is in the minimum of the range. max: 1 by default, if min \u003e max then max = 1. Specifies the value that datastream will take when the hardware channel value is in the maximum of the range es.amplia.oda.datastreams.i2c.cfg will have a similar format to:\nlightData=getter:false,setter:true,device:lightDev,min:0,max:10 temperatureData=device:temperatureDev ",
    "description": "",
    "tags": null,
    "title": "I2C",
    "uri": "/layers/datastreams/i2c/index.html"
  },
  {
    "content": "I2C This Hardware module allows to use the in/outputs provided by I2C bus.\nThis datastreams corresponds to the I2C devices connected to the device.\nTo access source code click here.\nDependencies This module requires the following modules:\nCommons: Provide API’s of I2C and the basic APIs to register the service. Configuration To configure I2C Hardware module, a file named es.amplia.oda.hardware.i2c.cfg must be created with the next parameters for each input channel that you want to register:\nname: Required parameter. Identifier name of the datastream. controller: Required parameter. Number of the controller of datastream. Controller and address form the direction to i2c source. address: Required parameter. Number of the address of datastream. Controller and address form the direction to i2c source. register: Required parameter. Position of the formed direction where the data of the datastream is stored. min: Required parameter, if min \u003e max then min = 0. Specifies the minimum value that the input value will reach when it’s at its minimum. max: Required parameter, if min \u003e max then max = 1. Specifies the maximum value that the input value will reach when it’s at its maximum. es.amplia.oda.hardware.i2c.cfg will have a similar format to:\nlight=controller:1,address:10,register:255,min:0,max:10 temperature=controller:2,address:10,register:124,min:-10,max:50 ",
    "description": "",
    "tags": null,
    "title": "I2C",
    "uri": "/layers/hardware/i2c/index.html"
  },
  {
    "content": "IEC 104 This connector enable communication via IEC 104 Protocol.\nAllow the transfer of data and operations with a SCADA third-system that implements an IEC 104 master (client).\nDependencies This module requires the following modules:\nCore Commons: Provides many interfaces that this module will use. Scada Dispatcher: Needed to process the payloads and de/serialize its content. Configuration To configure IEC 104 connector, a file named es.amplia.oda.connector.iec104.cfg must be created with the next parameters:\nlocalAddress: Required parameter. Specify the direction of the third system the connector have to send the data. ’localhost’ is a good host to do tests with. localPort: Required parameter. Port though the connector have to connect to the host. originatorAddress: Required parameter. Direction of the IEC104 client. commonAddress: Required parameter. Direction of the IEC104 slave the connector is using. spontaneousEnabled: Required parameter. Specify if the connector will send immediately the data or will alloc it in a cache waiting for a request from the master. In other words, es.amplia.oda.connector.iec104.cfg will have the content:\nlocalAddress=localhost localPort=2404 originatorAddress=0 commonAddress=1 spontaneousEnabled=true Source Code You can check the source code here\n",
    "description": "",
    "tags": null,
    "title": "IEC 104",
    "uri": "/layers/connectors/iec104/index.html"
  },
  {
    "content": "IEC104 This Datastream module defines the configuration needed to read data from an Iec104 device.\nTo access source code click here.\nDependencies This module requires the following modules:\nIEC104 Comms: Provide an implementation of IEC104 Master that the datastream module needs to connect with the devices. Scada Tables: Provide the information of the data to read from the iec104 device (ASDU type, address, datastreamID). Configuration To configure IEC104 Datastream module, a file named es.amplia.oda.datastreams.iec104.cfg must be created with the next parameters:\npollingTime: Required parameter. Indicates the time in seconds between Interrogation Command executions. Every x seconds, an Interrogation Command is sent to the iec104 device to retrieve data.\ndeviceId: Required parameter. Indicates the information needed to connect with device in the next format:\ndeviceId=ipAddress;port;commonAddress es.amplia.oda.datastreams.iec104.cfg will have a similar format to:\npollingTime=10000 devicejj2=127.0.0.1;2404;1 It is possible to define N devices with the format:\npollingTime=10000 devicejj1=127.0.0.1;2404;1 devicejj2=127.0.0.1;2404;2 devicejj3=127.0.0.2;2404;1 ",
    "description": "",
    "tags": null,
    "title": "IEC104",
    "uri": "/layers/datastreams/iec104/index.html"
  },
  {
    "content": "In Memory State Manager This State Manager stores the data of events to provide the actual value of a datastream quickly when the third system send a get request. This means, that the State Manager has an internal State that it refreshes every time that an event arrives.\nWhen an event arrives, the state manager applies the rules defined for that datastream and refreshes the stored value. The rules can change the value or not, either case the value is stored.\nThe state manager will send immediately to the third system the new value of the datastream if the rule engine checks this value as sendImmediately.\nWhen a get operation arrives, the state manager won’t get the value of the datastream directly. It will search if there is a value of that datastream into the state and will get it if exists. If the datastream doesn’t exists into the state, the state manager will get the value from the datastream normally.\nWhen a set operation arrives, the arrived value from the operation will be set into the datastream source directly, without any affect over the state of the state manager.\nA database is used to store a backup of datastreams stored in state. This backup is used to recover the datastreams not sent in case ODA stops working due to external causes.\nDependencies Core Commons: Provides the API of the configurable Bundles, Datastreams handling API’s and Device API’s. Rule Engine API: Provides a generic Rule Engine to contain the ODA rule engine and use it. Event API: Provides the event interface to handle the internal events of ODA. Configuration To configure State Manager InMemory, a file named es.amplia.oda.statemanager.inmemory.cfg must be created with the next parameters:\ndatabasePath: Required parameter. Specify the path where database will be located. maxData: Required parameter. Indicates the maximum number of values stored for each datastreamId, deviceId combination. forgetTime: Required parameter. Indicates the maximum antiquity, in seconds, of values to store. Values older than this will be removed. forgetPeriod:Required parameter. Indicates the periodicity in seconds that older values in database are removed. ",
    "description": "",
    "tags": null,
    "title": "In Memory State Manager",
    "uri": "/layers/statemanager/inmemory/index.html"
  },
  {
    "content": "JDK DIO Implementation of the library JDK DIO to give an access to digital in/outputs. This is the hardware module that give support to GPIO Datastreams.\nTo access source code click here.\nDependencies This module requires the following modules:\nCommons: Provide the GPIO APIs, exceptions and types and the basic APIs to register the service. Configuration To configure JDK DIO Hardware module, a file named es.amplia.oda.hardware.jdkdio.cfg must be created with the next parameters for each input channel that you want to register:\nindex: Required parameter. Index of the pin. deviceType: \"\" (void String) by default. Type of this pin. gpio.GPIOPin for specify an digital pin. name: Required parameter. Unique name for the pin. direction: OUTPUT by default. Specify if pin is open as in or out. Allowed directions are INPUT or OUTPUT. mode: OPEN_DRAIN by default. Specify the mode of the pin. Allowed modes are PULL_UP, PULL_DOWN, OPEN_DRAIN and PUSH_PULL. The first two are modes for OUTPUT pins and the last two are for INPUT pins. trigger: NONE by default. Trigger the pin changes the value. Allowed values are NONE, FALLING_EDGE, RISING_EDGE, BOTH_EDGES, LOW_LEVEL, HIGH_LEVEL, BOTH_LEVELS. For the outputs pins, as they doesn’t change value by themselves, the only one trigger valid is NONE. activeLow: false by default. ActiveLow option (reverses the values of the pin). True if activeLow is enabled. initialValue: false by default. Specify the initial value of the pin. On input pins this option can be changed quickly. es.amplia.oda.hardware.jdkdio.cfg will have a similar format to:\n1=deviceType:gpio.GPIOPin,name:lightOn 4=deviceType:gpio.GPIOPin,name:lightHigh,direction:input,mode:PUSH_PULL,trigger:LOW_LEVEL,activeLow:false,initialValue:true ",
    "description": "",
    "tags": null,
    "title": "JDK DIO",
    "uri": "/layers/hardware/jdkdio/index.html"
  },
  {
    "content": "ModBus Implementation of the library j2mod to give an access to devices connected through modbus. This is the hardware module that give support to Modbus Datastreams.\nTo access source code click here.\nDependencies This module requires the following modules:\nCommons: Provide the ModBus APIs, exceptions and types and the basic APIs to register the service. Configuration To configure ModBus Hardware module, a file named es.amplia.oda.hardware.modbus.cfg must be created with the next parameters:\ntype: Required data. Type of modbus connection. Allowed modbus types are TCP, UDP, Serial. connections: Required data for UDP and TCP. Indicates the devices and the data needed to connect with them. Allows multiple devices with the format : deviceId1,ipAddress1,port1;deviceId2,ipAddress2,port2;etc timeout: Required data for UDP and TCP. Time in seconds that the modbus hardware will wait until do a timeout if the master slave doesn’t respond. reconnect: Required data for TCP. Enable the option to reconnect automatically if connection is dropped. ports: Required data for serial. Indicates the name of the serial port (tty) and the deviceId associated. Allows multiple devices with the format : portName1,deviceId1;portName2,deviceId2;etc baudRate: Required data for serial. Baud Rate of the connection. 9600, 38400 or 115200. flowControlIn: Required data for serial. Flow Control of the input of connection. flowControlOut: Required data for serial. Flow Control of the output of connection. databits: Required data for serial. Data bits of the connection. 5, 6, 7 or 8. stopbits: Required data for serial. Stop bits of the connection. 1 or 2. parity: Required data for serial. Parity type of the connection. 0 is NONE parity, 1 is ODD parity, 2 is EVEN parity, 3 is mark parity and 4 is SPACE parity. encoding: Required data for serial. Encoding of the serial connection communication. E.g. ascii or rtu. echo: Required data for serial. Enable echo on the connection (show send data from local to the slave). es.amplia.oda.hardware.modbus.cfg will have a similar format to:\ntype=UDP timeout=30 connections=deviceId,localhost,30 type=TCP timeout=30 reconnect=true connections=deviceId,localhost,30 type=Serial ports=ttyUSB0,deviceId1 baudRate=115200 flowControlIn=1 flowControlOut=1 databits=8 stopbits=1 parity=0 encoding=ascii echo=true ",
    "description": "",
    "tags": null,
    "title": "ModBus",
    "uri": "/layers/hardware/modbus/index.html"
  },
  {
    "content": "MODBUS This Datastream module enable to register the datastreams of Modbus Hardware module.\nThis datastreams corresponds to the inputs/outputs obtained through modbus protocol.\nTo access source code click here.\nDependencies This module requires the following modules:\nModBus Hardware: Provide an implementation of ModBus Master that the datastream module need to connect to the bus and collect the information of each datastream. Configuration To configure ModBus Datastream module, a file named es.amplia.oda.datastreams.modbus.cfg must be created with the next parameters for each input channel that you want to register:\ndatastreamId: Required parameter. The identifier name of the datastream. deviceId: Required parameter. The device identifier name that contents the datastream. It also indicates the data needed to connect with device (defined in modbus hardware configuration file). datastreamType: Required parameter. Name of the Java class that is the datastream. Allowed classes are: Boolean, Byte[], Integer, Long, Short, Float, Double. slaveAddress: null if not present. Direction of the device in modbus. dataType: Required parameter. ModBus type of the data recollected from the modbus direction. Allowed classes are: INPUT_DISCRETE, COIL, INPUT_REGISTER, HOLDING_REGISTER dataAddress: null if not present. Direction of the specific data controlled by datastream inside the device. es.amplia.oda.datastreams.modbus.cfg will have a similar format to:\nlight=datastreamType:Long,slaveAddress:1,dataType:INPUT_DISCRETE,dataAddress:255 temp,testPi=datastreamType:DOUBLE,slaveAddress:2,dataType:INPUT_REGISTER,dataAddress:100 ",
    "description": "",
    "tags": null,
    "title": "MODBUS",
    "uri": "/layers/datastreams/modbus/index.html"
  },
  {
    "content": "MQTT This connector enable communication via MQTT Protocol.\nAllows to send data to the OpenGate platform and receive operations from it.\nDependencies This module requires the following modules:\nCore commons: Provides many interfaces that this module will use Mqtt Communications Module: Needed to create the MQTT client that will connects to the MQTT broker of the third system. Dispatcher: Needed to process the payloads and de/serialize its content. Device Info Provider: Needed to know the Device Id of the device that are running the Agent, and the API Key to access to OpenGate. Both data are required to achieve a connection with OpenGate and transferred data will have the deviceId in its metadata. Configuration To configure MQTT connector, a file named es.amplia.oda.connector.mqtt.cfg must be created with the next parameters:\nhost: Required parameter. Specify the direction of the third system the connector have to send the data. ’localhost’ is a good host to do tests with.\nport: 1883 by default. Port though the connector have to connect to the host.\nsecurePort: 8883 by default. Alternative port to connect securely.\nsecure: false by default. True to connect to the secure port, false to connect to common port.\nmqttVersion: MQTT_3_1_1 by default. Available options are MQTT_3_1, MQTT_3_1_1. MQTT version that connector has to use.\nkeepAliveInterval: 60 by default. Interval defined by MQTT client to communicate a keep alive message before to disconnect.\nmaxInFlight: 10 by default. Maximum messages that can be queued to be transmitted simultaneously.\ncleanSession: true by default. To specify if the connection is persistent (false) or not (true). If clean session is true, the broker doesn’t store information or messages.\nconnectionTimeout: 30 by default. Time that client will wait to achieve the connection.\nautomaticReconnect: true by default. If the connection fails and this option is true, enable the option to reconnect with the broker.\nlwt.topic: null if not specified. Topic where the client will receive all Last Will messages from another clients. Last Will messages are a pre-agreed message between the client, and the broker to send to the other clients in case of an unexpected disconnection.\nlwt.payload: null if not specified. LWT Payload is the data that the client will agree with the broker to send to another clients in case of connector’s client be disconnected unexpectedly.\nlwt.qos: 1 by default, if topic and payload are specified, will be 1 by default. Specify the qos of the LWT.\nlwt.retained: null if not specified, if topic and payload are specified, will be false by default. Specifies if the broker will send to the another clients the LW messages even when that clients connect to the broker after the connector’s client disconnect unexpectedly.\nkeyStore.path: null if not specified. Directory where the file of keys will be stored.\nkeyStore.type: null if not specified, if keyStore and trustStore path and password are specified, is JKS by default. The available options are: JKS, JCEKS, PKCS12, PKCS11, DKS, WINDOWS_MY, BKS. Is the type of the KeyStore that the connector will use.\nkeyStore.password: null if not specified. Password to access to the KeyStore.\nkeyManager.algorithm: null if not specified, *if keyStore and trustStore path and password are specified, is SunX509 by default. Available options are PKIX, SUN_X509, SUN_JSSE. Specify the algorithm used to handle the keys.\ntrustStore.path: null if not specified. Directory where the file of trust keys will be stored.\ntrustStore.type: null if not specified, if keyStore and trustStore path and password are specified, is JKS by default. The available options are: JKS, JCEKS, PKCS12, PKCS11, DKS, WINDOWS_MY, BKS. Is the type of the TrustStore that the connector will use.\ntrustStore.password: null if not specified. Password to access to the TrustStore.\ntrustManager.algorithm: null if not specified, *if keyStore and trustStore path and password are specified, is SunX509 by default. Available options are PKIX, SUN_X509, SUN_JSSE. Specify the algorithm used to handle the keys.\ntopic.iot: Required parameter. The topic to which the data transferred will be sent to the third-system (e.g. OpenGate).\ntopic.request: Required parameter. The topic to which the operations will be sent from the third-system to the ODA for processing.\ntopic.response: Required parameter. The topic to which the operations responses will be sent from the ODA to the third-system.\nmessage.qos: 1 by default. This parameter can be 0, 1 or 2. QOS that will have the messages sent by connector’s client. QOS is the level agreed between client and broker to ensure the delivery of the message.\nqos = 0 - at most once - Message is delivered at most once. Its delivery is not acknowledged. It may not be delivered at all. Fastest method. qos = 1 - at least once - Message is always delivered at least once. It might be delivered multiple times. qos = 2 - exactly once - Message is always delivered exactly once. Safest method but slowest. message.retained: false by default. If is true, the last message sent to broker will be sent to another clients even if those clients connects after the message was sent.\nconnection.initialDelay: 0 by default. Time wait by the connector’s client to try the initial connection to the broker.\nconnection.retryDelay: 300 by default. If first try fails, time that the connector’s client will wait before the next try to connect.\nThe file es.amplia.oda.connector.mqtt.cfg could have a lot of parameters, but it can works correctly with the next parameters:\nhost=localhost topic.request=odm/request topic.response=odm/response topic.iot=odm/iot message.qos=1 Source Code You can check the source code here\n",
    "description": "",
    "tags": null,
    "title": "MQTT",
    "uri": "/layers/connectors/mqtt/index.html"
  },
  {
    "content": "MQTT This datastreams corresponds to the enabling/disabling, writing and reading of datastreams allocated into another application that communicates with the ODA through MQTT protocol.\nUnlike the other datastreams, this doesn’t register the datastreams handled by configuration. This datastream configuration contains various topics in which the mqtt communication is made and where the module will subscribe when connection is achieved, having a topic for each function. To register a datastream, a message have to be sent to the enable datastream topic with the device id and the datastream id, i.e. to enable a datastream with id myDatastreamId of the device with id myDeviceId, we have to send a message to the topic oda/enable/myDeviceId/myDatastreamId.\nThe explained format is common in all the topics for all the functions. To operate on a datastream, we use the next topic format:\nexpectedTopic/deviceId/datastreamId To access source code click here.\nDependencies This module requires the following modules:\nMQTT Comms: Provide an implementation of MQTT Client Factory that the datastream module need to connect to the MQTT broker to provide information of each datastream and allow the operations. CBOR Serializer: Needed to transform the incoming messages to be readables by the modules and to serialize the outgoing payloads. Event Publisher: Used to handle the incoming events and send it. Configuration To configure I2C Datastream module, a file named es.amplia.oda.datastreams.mqtt.cfg must be created with the next parameters:\nbrokerURI: Required parameter. Direction where the MQTT client have to connect. clientId: selected at random by default. Identifier that the module client will have to connect to the broker enableDatastreamTopic: Required parameter. Topic where ODA expects the enables messages to be sent. disableDatastreamTopic: Required parameter. Topic where ODA expects the disables messages to be sent. eventTopic: Required parameter. Topic where ODA expects the events messages to be sent. readRequestTopic: Required parameter. Topic where ODA will send the request of reading operations. readResponseTopic: Required parameter. Topic where ODA expects the responses of read operations to be sent. writeRequestTopic: Required parameter. Topic where ODA will send the request of writing operations. writeResponseTopic: Required parameter. Topic where ODA expects the responses of write operations to be sent. lwtTopic: Required parameter. Topic where ODA expects the Last Will messages of another devices clients to be sent. es.amplia.oda.datastreams.mqtt.cfg. will have a similar format to:\nbrokerURI=tcp://localhost:1883 clientId=oda enableDatastreamTopic=oda/enable disableDatastreamTopic=oda/disable eventTopic=oda/event readRequestTopic=oda/operation/read/request readResponseTopic=oda/operation/read/response writeRequestTopic=oda/operation/write/request writeResponseTopic=oda/operation/write/response lwtTopic=oda/lwt Using the previous configuration example, ODA will use the next topics for the datastream “tempInCelsius” of the device “thermoDev”:\nFunction Topic used by oda enable oda/enable/thermoDev/tempInCelsius disable oda/disable/thermoDev/tempInCelsius event oda/event/thermoDev/tempInCelsius readRequest oda/operation/read/request/thermoDev/tempInCelsius readResponse oda/operation/read/response/thermoDev/tempInCelsius writeRequest oda/operation/write/request/thermoDev/tempInCelsius writeResponse oda/operation/write/response/thermoDev/tempInCelsius lwt oda/lwt/thermoDev/tempInCelsius ",
    "description": "",
    "tags": null,
    "title": "MQTT",
    "uri": "/layers/datastreams/mqtt/index.html"
  },
  {
    "content": "Nashorn With this implementation, the rules written in JavaScript have to be deployed into a directory specified by configuration.\nNashorn implementation will refresh its internal register of the current rules if a rule is deployed during runtime. To do this, rules related to a datastream have to be deployed into a directory with the name of the datastream into the deploy directory specified by configuration.\nIf no rule is refreshing the data of a datastream, a basic rule will refresh its value with the received value.\nDuring the engine, the datastreams can be checked as refreshed and as sendImmediately:\nRefreshed: This option represents that the value was already changed in the state that the rule engine is using and isn’t necessary to change with the base case, because is probably that the data has been derived. Send Immediately: This option represents that the value, received or the derived by it, have to be sent to the third system when all the rules have finished. It’s important to know that the rules can have conflicts if them overwrite a data that a previous rule has changed in the current state. The rules have not established order, so it’s impossible create the rules with an order in mind.\nThe same rule can be applied to different datastreams. To achieve this we must name the directory where the rule to apply is stored, with the different datastreamIds we want to affect, separated by the character ‘:’\nExample:\nWe want to apply rule.js to the datastreamIds Id1 and Id2. To do this, we must create a folder named Id1:Id2 and put the file rule.js in this directory.\nWe can also apply more than one rule to the same datastream. We can have more than one javascript file inside the folders. If a datastream is contained in the folder name, all javascript files inside that folder are going to be applied to that datastream.\nThere is a series of common methods that we can apply in rules that are preloaded for every rule. These methods are stored in the file utils.js that is stored in folder defined by parameter utilsPath. We can load another javascript file from within a rule with the instruction load(“javascript.js”) in the rule. The file javascript.js must be stored in the folder defined by parameter utilsPath. This allows us to define a javascript file with methods that are used in different rules.\nDependencies Core Commmons: Provide the basic API of the configurable bundle and an interface of a generic State Manager that the Engine can use to handle the rules. Event API: Provide the API of the internal events that use ODA to handle it. Rule Manager API: Provide the API of the Rule Engines that this module will implement. Configuration To configure Nashorn Rule Engine module, a file named es.amplia.oda.ruleengine.nashorn.cfg must be created with the next parameters:\npath: Required parameter. Path from the main directory of the ODA to the directory of the rules. utilsPath: Required parameter. Path from the main directory of the ODA to the directory where javascript files with utils for rules are stored. An example of the es.amplia.oda.ruleengine.nashorn.cfg file would be:\npath=rules/ utilsPath=jslib/ In this example, the ODA directory would be: /path/to/the/oda/directory. And the directory to the rules (inside the ODA directory) would be: /path/to/the/oda/directory/rules. This means, the path that the ODA would need is only path/.\n:::tip When specify the rule path, is important write the final bar of the directory. This is because the internal implementation wait that bar to append it to the specific datastream directory. :::\n",
    "description": "",
    "tags": null,
    "title": "Nashorn",
    "uri": "/layers/ruleengine/nashorn/index.html"
  },
  {
    "content": "Implement new operation To implement an operation in our bundle we must create a class that implements the interface CustomOperation.\nThis interface has two methods:\ngetOperationSatisfied - returns the Id of the operation\nexecute - this methods execute the operation\nAfter this class is implemented we must register the operation in the framework. We can do this using the class ServiceRegistration.\nServiceRegistration\u003cCustomOperation\u003e = bundleContext.registerService(CustomOperation.class, new TestCustomOperation(), null); To use this operation we must create the operation in OpenGate with the same name as the id defined in the CustomOperation class.\nWhen the operation its launched, ODA will check the Id with the operations registered in the framework and when it finds a match, it will launch the execute method of the operation.\n",
    "description": "",
    "tags": null,
    "title": "New operation",
    "uri": "/develop/customoperation/index.html"
  },
  {
    "content": "ODA ODA, responding to OpenGate Device Agent, is the software created by Amplía Soluciones S.L. to easily integrate your device data into our OpenGate IOT platform.\nOverview ODA is built using the OSGi specifications, a modular architecture that reduces complexity, increases reuse, eases deployment and provides dynamic updates.\nThe modular architecture allows tailoring a specific solution for a project in a few minutes, assembling the modules needed. You also taking advantage of a suite of highly tested and robust modules used on a big number of projects and situations.\nAdding your own business logic or protocols is also very easy. You just need to focus in the specific implementations, usually by implementing the interface of the service you want to provide, and integrate with the existing services.\nODA Architecture ODA is built on top of the Apache Felix Framework, an open source implementation of the OSGi Framework and Service platform, but is design to work with any of the OSGi framework implementations.\nInfrastructure The software provides a common infrastructure to be used from any module:\nComms : Communication modules used by different modules of the system (communication protocols used in WAN and LAN). Core: Core modules with common features. Services: Services to be used by any module (e.g. serialization services). Subsystems: General subsystems. Layers ODA follows a multi-tier architecture with the next layers:\nConnectors: Send and received data to/from the Internet at a low level of abstraction (byte array). Operation Dispatcher: Converts low level data into high level representation, usually using a Serializer, to get the operation request and send it to the right operation processor. Once the operation is processed, it converts the response into low level data to send it again through the connector. Event Dispatcher: Converts data events into a low level data representation to send it through the connectors. Operations: Implements a specific operation inside the device, like getting data, setting data or make a software update. It contains an interface to implement custom operations. State Manager: Stores the device data state in the current moment. May have historical information. Uses the rule engine if available to trigger custom business rules each time the data is updated. Rule Engine: Triggers custom business logic rules over the device data. Data Streams: Abstracts the data sources to ease the access to read and write data from the upper layers. Data sources may be GPIO, ADC, other devices connected through LAN protocols… Hardware: Abstracts the hardware specifics. ",
    "description": "",
    "tags": null,
    "title": "ODA official documentation",
    "uri": "/index.html"
  },
  {
    "content": "Real Time State Manager This State Manager will process directly any operation or event that arrives to it. This means, that the incoming value isn’t processed in the state manager and the rule engine is not used.\nWhen a event arrives, the state manager will send it directly to the third system, and the sent the value as it comes.\nWhen a get operation arrives, the state manager will get the value from the datastream source.\nWhen a set operation arrives, the arrived value from the operation will be setted into the datastream source directly, without any affect over the state of the state manager.\nDependencies Core Commons: Provides the API of the configurable Bundles, Datastreams handling API’s and Device API’s. Event API: Provides the event interface to handle the internal events of ODA. Configuration This bundle doesn’t requires any configuration.\n",
    "description": "",
    "tags": null,
    "title": "Real Time State Manager",
    "uri": "/layers/statemanager/realtime/index.html"
  },
  {
    "content": "Get Device Parameters This operation is used to get all the actual values of the datastreams registered by the ODA. This operation can take a while, depending on the number of registered datastreams (is like do a get of any datastream).\nValues getted by the operation will be passed to the state manager, which handle them according its implementation.\nDependencies Operation API: Provides the api of the operation and the enums of the result code. State Manager: Provides the API of the State Manager that will handle the returned value by the operation. Trace The trace send by the third system (e.g. OpenGate) to the ODA to do this operation is like this:\n‘{“operation”:{“request”:{“timestamp”:1571993751183,“deviceId”:“Tm1234”,“name”:“REFRESH_INFO”,“parameters”:[],“id”:“b949fabf-4734-46fe-937c-ea1e51fc2cf7”}}}’\n",
    "description": "",
    "tags": null,
    "title": "Refresh Info",
    "uri": "/layers/operations/refreshinfo/index.html"
  },
  {
    "content": "Set Clock This operation is used to set the local clock datastream (which is used to change the hour of the device) value to a value provided from the third system on the operation request itself. This value will be a long with a date in timestamp format.\nDependencies Commons: Required to provide the commons utils. Operation API: Provides the api of the operation and the enums of the result code. State Manager: Provides the API of the State Manager that will handle the returned value by the operation. Configuration To configure Set Clock Operation module, a file named es.amplia.oda.operation.setclock.cfg must be created with the next parameters:\nclockDatastream:Required parameter. Id of the datastream used to configure device clock. Trace The trace send by the third system (e.g. OpenGate) to the ODA to do this operation is like this:\n‘{“operation”:{“request”:{“timestamp”:1554978284595,“deviceId”:“aDevice”,“name”:“SET_CLOCK_EQUIPMENT”,“parameters”:[],“id”:“4aabb9c6-61ec-43ed-b0e4-dabface44b64”}}}’\n",
    "description": "",
    "tags": null,
    "title": "Set Clock",
    "uri": "/layers/operations/setclock/index.html"
  },
  {
    "content": "Set Device Parameters This operation is used to set the actual value of a datastream of the device, it means, to change the actual value.\nThe value setted by the operation will pass thrugh the State Manager and, depending of its implementation, will set the value of the datastream in some way.\nDependencies Operation API: Provides the api of the operation and the enums of the result code. State Manager: Provides the API of the State Manager that will handle the returned value by the operation. Trace The trace send by the third system (e.g. OpenGate) to the ODA to do this operation is like this:\n‘{“operation”:{“request”:{“timestamp”:1554978284595,“deviceId”:“Tm1234”,“name”:“SET_DEVICE_PARAMETERS”,“parameters”:[{“name”:“variableList”,“value”:{“array”:[{“variableName”:“q”,“variableValue”:17}]}}],“id”:“4aabb9c6-61ec-43ed-b0e4-dabface44b64”}}}’\n",
    "description": "",
    "tags": null,
    "title": "Set Device Parameters",
    "uri": "/layers/operations/setdeviceparameters/index.html"
  },
  {
    "content": "Simulator This Datastream module enable to register datastreams with a constant value or a random value between two numbers specified by parameters.\nTo access source code click here.\nDependencies This module have no dependencies\nConfiguration To configure ADC Datastream module, a file named es.amplia.oda.datastreams.simulator.cfg must be created with the next parameters for each input channel that you want to register:\nIn case of want to register a constant value:\ndatastreamId: Required parameter. Identifier of the datastream. deviceId: void string (\"\") by default. Identifier of the device that contents this datastream. dataType: Required data. Allowed values are: string, int, integer, float, double, number. Is th data-type of the datastream. constantValue: Required data. Value that always will return this datastream. In case of want a random numeric integer value:\ndatastreamId: Required parameter. Identifier of the datastream. deviceId: void string (\"\") by default. Identifier of the device that contents this datastream. minValue: Required data. Minimum value that the datastream can returns. maxValue: Required data. Maximum value that the datastream can returns. maxDiff: Required data. Percentage of the range that the value can change compared to the last. 100 if it doesn’t matter how much changes es.amplia.oda.datastreams.simulator.cfg will have a similar format to:\nconstantValue,testDevice=string,this is a test value randomValue=0,100,10 ",
    "description": "",
    "tags": null,
    "title": "Simulator",
    "uri": "/layers/datastreams/simulator/index.html"
  },
  {
    "content": "Synchronize Clock This operation is used to synchronize the local clock datastream (which is used to change the hour of the device) value to the value obtained doing a System.currentTimeMillis(). This value will be a long with a date in timestamp format.\nDependencies Commons: Required to provide the commons utils. Operation API: Provides the api of the operation and the enums of the result code. State Manager: Provides the API of the State Manager that will handle the returned value by the operation. Configuration To configure Set Clock Operation module, a file named es.amplia.oda.operation.synchronizeclock.cfg must be created with the next parameters:\nclockDatastream:Required parameter. Id of the datastream used to synchronize device clock. Trace The trace send by the third system (e.g. OpenGate) to the ODA to do this operation is like this:\n‘{“operation”:{“request”:{“timestamp”:1554978284595,“deviceId”:“aDevice”,“name”:“SYNCHRONIZE_CLOCK”,“parameters”:[],“id”:“4aabb9c6-61ec-43ed-b0e4-dabface44b64”}}}’\n",
    "description": "",
    "tags": null,
    "title": "Synchronize Clock",
    "uri": "/layers/operations/synchronizeclock/index.html"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "Tags",
    "uri": "/tags/index.html"
  },
  {
    "content": "Update This operation is used to install/change/delete a local file of the application by the third system.\nThe operation will specifies the steps that ODA have to do and the url where the new files can be download to change the actuals or create news.\nThis means that his operation can extend the actual Agent already installed into the device at runtime.\nDependencies Commons: Required to provide the commons utils. Operation API: Provides the api of the operation and the enums of the result code. Configuration To configure Update Operation module, a file named es.amplia.oda.operation.update.cfg must be created with the next parameters:\nrulesPath:Required parameter. Path where rules will be installed. rulesUtilsPath:Required parameter. Path where rules utils files will be installed. backupPath:Required parameter. Path where backups of files to update will be stored. deployPath:Required parameter. Path where bundles will be deployed. downloadsPath:Required parameter. Path where downloaded files will be stored. configurationPath:Required parameter. Path where configuration files will be installed. Trace The trace send by the third system (e.g. OpenGate) to the ODA to do this operation is like this:\n‘{“operation”:{“request”:{“timestamp”:1557395219834,“name”:“UPDATE”,“parameters”:[{“name”:“bundleName”,“value”:{“string”:“rules-creation-test”}},{“name”:“bundleVersion”,“value”:{“string”:“2.0.0”}},{“name”:“deploymentElements”,“type”:“string”,“value”:{“array”:[{“name”:\"\" + this.name + “”,“version”:“2.0.0”,“type”:“SOFTWARE”,“downloadUrl”:“http://” + jschData.getSSH_SERVER_IP() + “:” + PORT_HTTP_SERVER + “/echoGet”,“path”:“rules/” + this.datastreamId + “”,“order”:1,“operation”:“INSTALL”,“validators”:[],“size”:334,“oldVersion”:“1.0.0”}]}}],“id”:“48589c6e-3d9f-4e59-a066-81f357fb6cf8”}}}’'\n",
    "description": "",
    "tags": null,
    "title": "Update",
    "uri": "/layers/operations/update/index.html"
  },
  {
    "content": "Functions of Utils.js Here they are collected all the functions that utils.js provide to use in the rules.\nControl Getting values getDatastreamValue\nFunction: Get the last value from the historic of a datastream in DatastreamValue object format.\nInput: Actual State of data (state) to use its operations and the metadata (deviceId and datastreamId) of the datastream that function have to get last value.\nOutput: The last value of the specified datastream in DatastreamValue format.\ngetValue\nFunction: Obtain from the State the Object Value associated with the datastream id that is passed by parameter.\nInput: Actual State of data (state) to use its operations and the metadata (deviceId and datastreamId) of the datastream that function have to get last value.\nOutput: The last value of the specified datastream in Object format with the class of the value.\nHandling datastream value object getDatastreamIdFromDatastreamValue\nFunction: Get the datastreamId (String) from a DatastreamValue object.\nInput: DatastreamValue object that the function have to get its datastreamId.\nOutput: Datastream id of input DatastreamValue.\ngetDeviceIdFromDatastreamValue\nFunction: Get the deviceId (String) from a DatastreamValue object.\nInput: DatastreamValue object that the function have to get its deviceId.\nOutput: Device id of input DatastreamValue.\ngetValueFromDatastreamValue\nFunction: Obtain the real value of passed DatastreamValue Object.\nInput: DatastreamValue object that the function have to get its value.\nOutput: Real value of the DatastreamValue.\nAdding values setValueFromDatastreamValue\nFunction: Change the last value of a existing datastream, using a DatastreamValue object as input to change the value. Input: Actual state of the stateManager (state), a String that specified the device id (deviceId), a String that specifies the datastream id (datastreamId) and new DatastreamValue for that datastream (value).\nOutput: Refreshed state with the new value set as last value of the datastream.\nsetValue\nFunction: Change the last value of a existing datastream, using a real value in simply format (boolean, string, integer, etc.) as input. Input: Actual state of the stateManager (state), a String that specified the device id (deviceId), a String that specifies the datastream id (datastreamId) and new value for that datastream (value).\nOutput: Refreshed state with the new value set as last value of the datastream.\nsetValueWithTime\nFunction: Change the last value of a existing datastream, using a real value in simply format (boolean, string, integer, etc.) as input. It allows to specify the time of the datastream. Input: Actual state of the stateManager (state), a String that specified the device id (deviceId), a String that specifies the datastream id (datastreamId), the time to set in the datastream and new value for that datastream (value).\nOutput: Refreshed state with the new value and time set as last value of the datastream.\nFilter filterBetween\nFunction: Filter the value between a minimum and a maximum (both included) and return a true if and only if value is between.\nInput:\nvalue: Object Value that we are filtering. min: Minimum value that we are expecting from value. max: Maximum value that we are expecting from value. Output: True if and only if value is between min and max, false in another case.\nfilterLessOrEqualsThan\nFunction: Filter the value under a maximum value (including that value) and return true if is less than max.\nInput:\nvalue: Object Value that we are filtering. max: Maximum value that we are expecting from value. Output: True if and only if value is less or equals than max, false in another case.\nfilterMoreOrEqualsThan\nFunction: Filter the value over a minimum value (including that value) and return true if is less than min.\nInput:\nvalue: Object Value that we are filtering. min: Minimum value that we are expecting from value. Output: True if and only if value is less or equals than min, false in another case.\nfilterLessThan\nFunction: Filter the value under a maximum value and return true if is less than max.\nInput:\nvalue: Object Value that we are filtering. max: Maximum value that we are expecting from value. Output: True if and only if value is less than max, false in another case.\nfilterEqualsThan\nFunction: Filter if the value is the specified and return true if is exactly than data.\nInput:\nvalue: Object Value that we are filtering. data: Value that we are expecting from value. Output: True if and only if value is the specified, false in another case.\nfilterMoreThan\nFunction: Filter the value over a minimum value and return true if is more than min.\nInput:\nvalue: Object Value that we are filtering. min: Minimum value that we are expecting from value. Output: True if and only if value is more than min, false in another case.\nfilterExpectedValues\nFunction: Filter if the value exists in a list of values and return true if it exists.\nInput:\nvalue: Object Value that we are filtering. expected: Array of values that we are expecting from value. Output: True if and only if value is in expected, false in another case.\nDerived sum\nFunction: Add a quantity to the actual value. To create a new Object Value, we need the state, that is the Java object that handle that creation.\nInput:\nstate: State object that we will use to create the new Object Value. value: Object Value that we want to add the quantity. quantity: Quantity to add to the value. Output: New Object Value with the real value modified.\nsub\nFunction: Subtract a quantity to the actual value. To create a new Object Value, we need the state, that is the Java object that handle that creation.\nInput:\nstate: State object that we will use to create the new Object Value. value: Object Value that we want to subtract the quantity. quantity: Quantity to subtract to the value. Output: New Object Value with the real value modified.\nmult\nFunction: Multiply a quantity by the actual value. To create a new Object Value, we need the state, that is the Java object that handle that creation.\nInput:\nstate: State object that we will use to create the new Object Value. value: Object Value that we want to multiply by the quantity. quantity: Quantity to multiply the value. Output: New Object Value with the real value modified.\ndiv\nFunction: Divide a quantity by the actual value. To create a new Object Value, we need the state, that is the Java object that handle that creation.\nInput:\nstate: State object that we will use to create the new Object Value. value: Object Value that we want to divide by the quantity. quantity: Quantity to divide the value. Output: New Object Value with the real value modified.\nUtils conditionalValue\nFunction: Like a Ternary Operator, return a value if the condition is true and another value if the condition is false.\nInput:\ncondition: bool value that control what value will be returned in a new Object Value. deviceId: String with the deviceId of the Object Value. datastreamId: String with the datastreamId of the Object Value. valueTrue: value what be set in the created Object Value if condition is true. valueFalse: value what be set in the created Object Value if condition is false. state: actual state to use its functions to refresh its data. Output: New Object Value with the new value, valueTrue if condition is true and valueFalse if condition is false.\nexists\nFunction: Check if a datastream is registered in the state.\nInput:\nstate: Current state of the State Manager. datastreamIdRequired: Id of the datastream that we are looking for. Output: Return true if the datastream is in the state and false if not.\nsendImmediately\nFunction: Mark the datastream to send immediately when all rules are resolved.\nInput: The device id (String) and the datastream id (String) of the datastream that function have to mark.\nOutput: Nothing, only refresh the state data.\n",
    "description": "",
    "tags": null,
    "title": "Utils",
    "uri": "/layers/ruleengine/utils/index.html"
  },
  {
    "content": "WebSocket This connector enable communication via WebSocket Protocol.\nAllows to send data to the OpenGate platform and receive operations from it.\nDependencies This module requires the following modules:\nCore commons: Provides many interfaces that this module will use Device Info Provider: Needed to know the Device Id of the device that are running the Agent and the API Key to access to OpenGate. Both data are required to achieve a connection with OpenGate and transferred data will have the deviceId in its metadata. Dispatcher: Needed to process the payloads and de/serialize its content. Configuration To configure WebSocket connector, a file named es.amplia.oda.connector.websocket.cfg must be created with the next parameters:\nhost: Required parameter. Specify the direction of the third system the connector have to send the data. ’localhost’ is a good host to do tests with. port: 80 by default. Port though the connector have to connect to the host. path: Required parameter. The general path of the route used to create the connection with third system. connectionTimeout: 30 by default. Time in seconds that the client created by the connector will wait to throw a timeout. keepAliveInterval: 180 by default. Time in seconds that the client created by the connector will send a KeepAlive message to notify to the WebSocket server. In other words, es.amplia.oda.connector.websocket.cfg will have the content:\nhost=localhost port=80 path=commonPathToAllSites connectionTimeout=30 keepAliveInterval=180 And can run with the following minimal content:\nhost=localhost generalPath=commonPathToAllSites Source Code You can check the source code here\n",
    "description": "",
    "tags": null,
    "title": "WebSocket",
    "uri": "/layers/connectors/websocket/index.html"
  }
]
